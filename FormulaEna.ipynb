{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T00:05:04.397024Z",
     "iopub.status.busy": "2024-07-26T00:05:04.396612Z",
     "iopub.status.idle": "2024-07-26T00:05:05.049064Z",
     "shell.execute_reply": "2024-07-26T00:05:05.048407Z",
     "shell.execute_reply.started": "2024-07-26T00:05:04.397003Z"
    },
    "id": "ZwlNp-76idJe",
    "outputId": "f6591f14-c93f-4df7-d8bb-d1d4a62b5330"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import relbench\n",
    "\n",
    "relbench.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6DWB-Kf6nl2y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "\n",
    "dataset = get_dataset(\"rel-f1\", download=True)\n",
    "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
    "\n",
    "train_table = task.get_table(\"train\")\n",
    "val_table = task.get_table(\"val\")\n",
    "test_table = task.get_table(\"test\")\n",
    "\n",
    "out_channels = 1\n",
    "loss_fn = L1Loss()\n",
    "tune_metric = \"mae\"\n",
    "higher_is_better = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKFT5H51j_Um"
   },
   "source": [
    "Let's check out the training table just to make sure it looks fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABN_fdN3kAB9",
    "outputId": "afb2d6b1-a54f-4b68-b6d1-5894ec7b3b87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table(df=\n",
       "           date  driverId  position\n",
       "0    2004-07-05        10     10.75\n",
       "1    2004-07-05        47     12.00\n",
       "2    2004-03-07         7     15.00\n",
       "3    2004-01-07        10      9.00\n",
       "4    2003-09-09        52     13.00\n",
       "...         ...       ...       ...\n",
       "7448 1995-08-22        96     15.75\n",
       "7449 1975-06-08       228      8.00\n",
       "7450 1965-05-31       418     16.00\n",
       "7451 1961-08-20       467     37.00\n",
       "7452 1954-05-29       677     30.00\n",
       "\n",
       "[7453 rows x 3 columns],\n",
       "  fkey_col_to_pkey_table={'driverId': 'drivers'},\n",
       "  pkey_col=None,\n",
       "  time_col=date)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQhuHIdHkOxv"
   },
   "source": [
    "Note that to load the data we did not require any deep learning libraries. Now we introduce the PyTorch Frame library, which is useful for encoding individual tables into initial node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNzfdwsrkPIo",
    "outputId": "0bb44a5f-ea16-40fe-db25-6868ac05ef99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_frame\n",
    "\n",
    "# Some book keeping\n",
    "from torch_geometric.seed import seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # check that it's cuda if you want it to run in reasonable time!\n",
    "root_dir = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Y79g5H0kVjX"
   },
   "source": [
    "The first big move is to build a graph out of the database. Here we use our pre-prepared conversion function.\n",
    "\n",
    "The source code can be found at: https://github.com/snap-stanford/relbench/blob/main/relbench/modeling/graph.py\n",
    "\n",
    "Each node in the graph corresonds to a single row in the database. Crucially, PyTorch Frame stores whole tables as objects in a way that is compatibile with PyG minibatch sampling, meaning we can sample subgraphs as in https://arxiv.org/abs/1706.02216, and retrieve the relevant raw features.\n",
    "\n",
    "PyTorch Frame also stores the `stype` (i.e., modality) of each column, and any specialized feature encoders (e.g., text encoders) to be used later. So we need to configure the `stype` for each column, for which we use a function that tries to automatically detect the `stype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kiV3TGI-kRuy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lema/.cache/relbench/rel-f1/db...\n",
      "Done in 0.05 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'constructors': {'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'constructorRef': <stype.text_embedded: 'text_embedded'>,\n",
       "  'name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'nationality': <stype.text_embedded: 'text_embedded'>},\n",
       " 'circuits': {'circuitId': <stype.numerical: 'numerical'>,\n",
       "  'circuitRef': <stype.text_embedded: 'text_embedded'>,\n",
       "  'name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'location': <stype.text_embedded: 'text_embedded'>,\n",
       "  'country': <stype.text_embedded: 'text_embedded'>,\n",
       "  'lat': <stype.numerical: 'numerical'>,\n",
       "  'lng': <stype.numerical: 'numerical'>,\n",
       "  'alt': <stype.numerical: 'numerical'>},\n",
       " 'races': {'raceId': <stype.numerical: 'numerical'>,\n",
       "  'year': <stype.categorical: 'categorical'>,\n",
       "  'round': <stype.numerical: 'numerical'>,\n",
       "  'circuitId': <stype.numerical: 'numerical'>,\n",
       "  'name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>,\n",
       "  'time': <stype.timestamp: 'timestamp'>},\n",
       " 'drivers': {'driverId': <stype.numerical: 'numerical'>,\n",
       "  'driverRef': <stype.text_embedded: 'text_embedded'>,\n",
       "  'code': <stype.text_embedded: 'text_embedded'>,\n",
       "  'forename': <stype.text_embedded: 'text_embedded'>,\n",
       "  'surname': <stype.text_embedded: 'text_embedded'>,\n",
       "  'dob': <stype.timestamp: 'timestamp'>,\n",
       "  'nationality': <stype.text_embedded: 'text_embedded'>},\n",
       " 'constructor_standings': {'constructorStandingsId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'wins': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'standings': {'driverStandingsId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'driverId': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'wins': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'constructor_results': {'constructorResultsId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'results': {'resultId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'driverId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'number': <stype.numerical: 'numerical'>,\n",
       "  'grid': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'positionOrder': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'laps': <stype.numerical: 'numerical'>,\n",
       "  'milliseconds': <stype.numerical: 'numerical'>,\n",
       "  'fastestLap': <stype.numerical: 'numerical'>,\n",
       "  'rank': <stype.numerical: 'numerical'>,\n",
       "  'statusId': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'qualifying': {'qualifyId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'driverId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'number': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from relbench.modeling.utils import get_stype_proposal\n",
    "\n",
    "db = dataset.get_db()\n",
    "col_to_stype_dict = get_stype_proposal(db)\n",
    "col_to_stype_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPK7hYz_fTJo",
    "outputId": "36491c17-4ef1-494c-fa86-1266884cee5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['constructors', 'circuits', 'races', 'drivers', 'constructor_standings', 'standings', 'constructor_results', 'results', 'qualifying'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.table_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "taqsrgZ0fiPs",
    "outputId": "6033c45e-3307-45be-e37c-eab207dccd30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circuitId</th>\n",
       "      <th>circuitRef</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>albert_park</td>\n",
       "      <td>Albert Park Grand Prix Circuit</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Australia</td>\n",
       "      <td>-37.84970</td>\n",
       "      <td>144.96800</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sepang</td>\n",
       "      <td>Sepang International Circuit</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2.76083</td>\n",
       "      <td>101.73800</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bahrain</td>\n",
       "      <td>Bahrain International Circuit</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>26.03250</td>\n",
       "      <td>50.51060</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>catalunya</td>\n",
       "      <td>Circuit de Barcelona-Catalunya</td>\n",
       "      <td>Montmeló</td>\n",
       "      <td>Spain</td>\n",
       "      <td>41.57000</td>\n",
       "      <td>2.26111</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>Istanbul Park</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.95170</td>\n",
       "      <td>29.40500</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>portimao</td>\n",
       "      <td>Autódromo Internacional do Algarve</td>\n",
       "      <td>Portimão</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>37.22700</td>\n",
       "      <td>-8.62670</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>mugello</td>\n",
       "      <td>Autodromo Internazionale del Mugello</td>\n",
       "      <td>Mugello</td>\n",
       "      <td>Italy</td>\n",
       "      <td>43.99750</td>\n",
       "      <td>11.37190</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>jeddah</td>\n",
       "      <td>Jeddah Corniche Circuit</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>21.63190</td>\n",
       "      <td>39.10440</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>losail</td>\n",
       "      <td>Losail International Circuit</td>\n",
       "      <td>Al Daayen</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>25.49000</td>\n",
       "      <td>51.45420</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>miami</td>\n",
       "      <td>Miami International Autodrome</td>\n",
       "      <td>Miami</td>\n",
       "      <td>USA</td>\n",
       "      <td>25.95810</td>\n",
       "      <td>-80.23890</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    circuitId   circuitRef                                  name  \\\n",
       "0           0  albert_park        Albert Park Grand Prix Circuit   \n",
       "1           1       sepang          Sepang International Circuit   \n",
       "2           2      bahrain         Bahrain International Circuit   \n",
       "3           3    catalunya        Circuit de Barcelona-Catalunya   \n",
       "4           4     istanbul                         Istanbul Park   \n",
       "..        ...          ...                                   ...   \n",
       "72         72     portimao    Autódromo Internacional do Algarve   \n",
       "73         73      mugello  Autodromo Internazionale del Mugello   \n",
       "74         74       jeddah               Jeddah Corniche Circuit   \n",
       "75         75       losail          Losail International Circuit   \n",
       "76         76        miami         Miami International Autodrome   \n",
       "\n",
       "        location       country       lat        lng    alt  \n",
       "0      Melbourne     Australia -37.84970  144.96800   10.0  \n",
       "1   Kuala Lumpur      Malaysia   2.76083  101.73800   18.0  \n",
       "2         Sakhir       Bahrain  26.03250   50.51060    7.0  \n",
       "3       Montmeló         Spain  41.57000    2.26111  109.0  \n",
       "4       Istanbul        Turkey  40.95170   29.40500  130.0  \n",
       "..           ...           ...       ...        ...    ...  \n",
       "72      Portimão      Portugal  37.22700   -8.62670  108.0  \n",
       "73       Mugello         Italy  43.99750   11.37190  255.0  \n",
       "74        Jeddah  Saudi Arabia  21.63190   39.10440   15.0  \n",
       "75     Al Daayen         Qatar  25.49000   51.45420   15.0  \n",
       "76         Miami           USA  25.95810  -80.23890    2.0  \n",
       "\n",
       "[77 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = db.table_dict[\"circuits\"].df\n",
    "# table[table[\"alt\"].isnull()]\n",
    "table\n",
    "# set missing alt\n",
    "table.loc[75, \"alt\"] = 15\n",
    "table.loc[76, \"alt\"] = 2\n",
    "table.loc[22, \"alt\"] = 634\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Bz0lobfxFh",
    "outputId": "9f129fb9-4ff8-4bda-c837-e1cc8b53bad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructors\n",
      "     constructorId constructorRef            name nationality\n",
      "0                0        mclaren         McLaren     British\n",
      "1                1     bmw_sauber      BMW Sauber      German\n",
      "2                2       williams        Williams     British\n",
      "3                3        renault         Renault      French\n",
      "4                4     toro_rosso      Toro Rosso     Italian\n",
      "..             ...            ...             ...         ...\n",
      "206            206          manor  Manor Marussia     British\n",
      "207            207           haas    Haas F1 Team    American\n",
      "208            208   racing_point    Racing Point     British\n",
      "209            209     alphatauri      AlphaTauri     Italian\n",
      "210            210         alpine  Alpine F1 Team      French\n",
      "\n",
      "[211 rows x 4 columns]\n",
      "[]\n",
      "circuits\n",
      "    circuitId   circuitRef                                  name  \\\n",
      "0           0  albert_park        Albert Park Grand Prix Circuit   \n",
      "1           1       sepang          Sepang International Circuit   \n",
      "2           2      bahrain         Bahrain International Circuit   \n",
      "3           3    catalunya        Circuit de Barcelona-Catalunya   \n",
      "4           4     istanbul                         Istanbul Park   \n",
      "..        ...          ...                                   ...   \n",
      "72         72     portimao    Autódromo Internacional do Algarve   \n",
      "73         73      mugello  Autodromo Internazionale del Mugello   \n",
      "74         74       jeddah               Jeddah Corniche Circuit   \n",
      "75         75       losail          Losail International Circuit   \n",
      "76         76        miami         Miami International Autodrome   \n",
      "\n",
      "        location       country       lat        lng    alt  \n",
      "0      Melbourne     Australia -37.84970  144.96800   10.0  \n",
      "1   Kuala Lumpur      Malaysia   2.76083  101.73800   18.0  \n",
      "2         Sakhir       Bahrain  26.03250   50.51060    7.0  \n",
      "3       Montmeló         Spain  41.57000    2.26111  109.0  \n",
      "4       Istanbul        Turkey  40.95170   29.40500  130.0  \n",
      "..           ...           ...       ...        ...    ...  \n",
      "72      Portimão      Portugal  37.22700   -8.62670  108.0  \n",
      "73       Mugello         Italy  43.99750   11.37190  255.0  \n",
      "74        Jeddah  Saudi Arabia  21.63190   39.10440   15.0  \n",
      "75     Al Daayen         Qatar  25.49000   51.45420   15.0  \n",
      "76         Miami           USA  25.95810  -80.23890    2.0  \n",
      "\n",
      "[77 rows x 8 columns]\n",
      "[]\n",
      "races\n",
      "     raceId  year  round  circuitId                  name                date  \\\n",
      "0         0  1950      1          8    British Grand Prix 1950-05-13 00:00:00   \n",
      "1         1  1950      2          5     Monaco Grand Prix 1950-05-21 00:00:00   \n",
      "2         2  1950      3         18      Indianapolis 500 1950-05-30 00:00:00   \n",
      "3         3  1950      4         65      Swiss Grand Prix 1950-06-04 00:00:00   \n",
      "4         4  1950      5         12    Belgian Grand Prix 1950-06-18 00:00:00   \n",
      "..      ...   ...    ...        ...                   ...                 ...   \n",
      "815     815  2009     13         13    Italian Grand Prix 2009-09-13 12:00:00   \n",
      "816     816  2009     14         14  Singapore Grand Prix 2009-09-27 12:00:00   \n",
      "817     817  2009     15         21   Japanese Grand Prix 2009-10-04 05:00:00   \n",
      "818     818  2009     16         17  Brazilian Grand Prix 2009-10-18 16:00:00   \n",
      "819     819  2009     17         23  Abu Dhabi Grand Prix 2009-11-01 11:00:00   \n",
      "\n",
      "         time  \n",
      "0    00:00:00  \n",
      "1    00:00:00  \n",
      "2    00:00:00  \n",
      "3    00:00:00  \n",
      "4    00:00:00  \n",
      "..        ...  \n",
      "815  12:00:00  \n",
      "816  12:00:00  \n",
      "817  05:00:00  \n",
      "818  16:00:00  \n",
      "819  11:00:00  \n",
      "\n",
      "[820 rows x 7 columns]\n",
      "[]\n",
      "drivers\n",
      "     driverId        driverRef code  forename     surname        dob  \\\n",
      "0           0         hamilton  HAM     Lewis    Hamilton 1985-01-07   \n",
      "1           1         heidfeld  HEI      Nick    Heidfeld 1977-05-10   \n",
      "2           2          rosberg  ROS      Nico     Rosberg 1985-06-27   \n",
      "3           3           alonso  ALO  Fernando      Alonso 1981-07-29   \n",
      "4           4       kovalainen  KOV    Heikki  Kovalainen 1981-10-19   \n",
      "..        ...              ...  ...       ...         ...        ...   \n",
      "852       852  mick_schumacher  MSC      Mick  Schumacher 1999-03-22   \n",
      "853       853             zhou  ZHO    Guanyu        Zhou 1999-05-30   \n",
      "854       854         de_vries  DEV      Nyck    de Vries 1995-02-06   \n",
      "855       855          piastri  PIA     Oscar     Piastri 2001-04-06   \n",
      "856       856         sargeant  SAR     Logan    Sargeant 2000-12-31   \n",
      "\n",
      "    nationality  \n",
      "0       British  \n",
      "1        German  \n",
      "2        German  \n",
      "3       Spanish  \n",
      "4       Finnish  \n",
      "..          ...  \n",
      "852      German  \n",
      "853     Chinese  \n",
      "854       Dutch  \n",
      "855  Australian  \n",
      "856    American  \n",
      "\n",
      "[857 rows x 7 columns]\n",
      "[]\n",
      "constructor_standings\n",
      "       constructorStandingsId  raceId  constructorId  points  position  wins  \\\n",
      "0                           0      64            103     3.0         3     0   \n",
      "1                           1      64              5     6.0         2     0   \n",
      "2                           2      64             85     8.0         1     1   \n",
      "3                           3      65             85    16.0         1     2   \n",
      "4                           4      65             31     0.0         5     0   \n",
      "...                       ...     ...            ...     ...       ...   ...   \n",
      "10165                   10165     819              3    26.0         8     0   \n",
      "10166                   10166     819              1    36.0         6     0   \n",
      "10167                   10167     819              2    34.5         7     0   \n",
      "10168                   10168     819              4     8.0        10     0   \n",
      "10169                   10169     819              9    13.0         9     0   \n",
      "\n",
      "                     date  \n",
      "0     1958-01-19 00:00:00  \n",
      "1     1958-01-19 00:00:00  \n",
      "2     1958-01-19 00:00:00  \n",
      "3     1958-05-18 00:00:00  \n",
      "4     1958-05-18 00:00:00  \n",
      "...                   ...  \n",
      "10165 2009-11-01 11:00:00  \n",
      "10166 2009-11-01 11:00:00  \n",
      "10167 2009-11-01 11:00:00  \n",
      "10168 2009-11-01 11:00:00  \n",
      "10169 2009-11-01 11:00:00  \n",
      "\n",
      "[10170 rows x 7 columns]\n",
      "[]\n",
      "standings\n",
      "       driverStandingsId  raceId  driverId  points  position  wins  \\\n",
      "0                      0       0       789     0.0        20     0   \n",
      "1                      1       0       640     0.0        18     0   \n",
      "2                      2       0       589     0.0        19     0   \n",
      "3                      3       0       669     0.0        15     0   \n",
      "4                      4       0       661     0.0        22     0   \n",
      "...                  ...     ...       ...     ...       ...   ...   \n",
      "28110              28110     819         7    48.0         6     1   \n",
      "28111              28111     819        68     0.0        25     0   \n",
      "28112              28112     819        11     0.0        21     0   \n",
      "28113              28113     819         6     2.0        19     0   \n",
      "28114              28114     819        12    22.0        11     0   \n",
      "\n",
      "                     date  \n",
      "0     1950-05-13 00:00:00  \n",
      "1     1950-05-13 00:00:00  \n",
      "2     1950-05-13 00:00:00  \n",
      "3     1950-05-13 00:00:00  \n",
      "4     1950-05-13 00:00:00  \n",
      "...                   ...  \n",
      "28110 2009-11-01 11:00:00  \n",
      "28111 2009-11-01 11:00:00  \n",
      "28112 2009-11-01 11:00:00  \n",
      "28113 2009-11-01 11:00:00  \n",
      "28114 2009-11-01 11:00:00  \n",
      "\n",
      "[28115 rows x 7 columns]\n",
      "[]\n",
      "constructor_results\n",
      "      constructorResultsId  raceId  constructorId  points                date\n",
      "0                        0      48            103    13.0 1956-01-22 00:00:00\n",
      "1                        1      48              5    12.0 1956-01-22 00:00:00\n",
      "2                        2      54            126     0.0 1956-08-05 00:00:00\n",
      "3                        3      54            103    15.0 1956-08-05 00:00:00\n",
      "4                        4      54              5     9.0 1956-08-05 00:00:00\n",
      "...                    ...     ...            ...     ...                 ...\n",
      "9403                  9403     819              5     0.0 2009-11-01 11:00:00\n",
      "9404                  9404     819              0     0.0 2009-11-01 11:00:00\n",
      "9405                  9405     819              2     0.0 2009-11-01 11:00:00\n",
      "9406                  9406     819              4     1.0 2009-11-01 11:00:00\n",
      "9407                  9407     819              6     5.0 2009-11-01 11:00:00\n",
      "\n",
      "[9408 rows x 5 columns]\n",
      "[]\n",
      "results\n",
      "       resultId  raceId  driverId  constructorId  number  grid  position  \\\n",
      "0             0       0       660            152    18.0    21      11.0   \n",
      "1             1       0       790            149     8.0    12       NaN   \n",
      "2             2       0       579             49     1.0     3       NaN   \n",
      "3             3       0       661            149     9.0    10       NaN   \n",
      "4             4       0       789            152    17.0     7       NaN   \n",
      "...         ...     ...       ...            ...     ...   ...       ...   \n",
      "20318     20318     819         1              1     6.0     8       5.0   \n",
      "20319     20319     819        21             22    23.0     4       4.0   \n",
      "20320     20320     819        17             22    22.0     5       3.0   \n",
      "20321     20321     819        16              8    14.0     3       2.0   \n",
      "20322     20322     819         2              2    16.0     9       9.0   \n",
      "\n",
      "       positionOrder  points  laps  milliseconds  fastestLap  rank  statusId  \\\n",
      "0                 11     0.0    64           NaN         NaN   NaN        16   \n",
      "1                 21     0.0     2           NaN         NaN   NaN       126   \n",
      "2                 12     0.0    62           NaN         NaN   NaN        44   \n",
      "3                 20     0.0     5           NaN         NaN   NaN         6   \n",
      "4                 19     0.0     8           NaN         NaN   NaN        51   \n",
      "...              ...     ...   ...           ...         ...   ...       ...   \n",
      "20318              5     4.0    55     5669667.0        54.0   7.0         1   \n",
      "20319              4     5.0    55     5666149.0        54.0   4.0         1   \n",
      "20320              3     6.0    55     5661881.0        49.0   6.0         1   \n",
      "20321              2     8.0    55     5661271.0        14.0   5.0         1   \n",
      "20322              9     0.0    55     5689355.0        49.0  15.0         1   \n",
      "\n",
      "                     date  \n",
      "0     1950-05-13 00:00:00  \n",
      "1     1950-05-13 00:00:00  \n",
      "2     1950-05-13 00:00:00  \n",
      "3     1950-05-13 00:00:00  \n",
      "4     1950-05-13 00:00:00  \n",
      "...                   ...  \n",
      "20318 2009-11-01 11:00:00  \n",
      "20319 2009-11-01 11:00:00  \n",
      "20320 2009-11-01 11:00:00  \n",
      "20321 2009-11-01 11:00:00  \n",
      "20322 2009-11-01 11:00:00  \n",
      "\n",
      "[20323 rows x 15 columns]\n",
      "['number', 'position', 'milliseconds', 'fastestLap', 'rank']\n",
      "qualifying\n",
      "      qualifyId  raceId  driverId  constructorId  number  position  \\\n",
      "0             0     548        43             26      26        19   \n",
      "1             1     548       100             30      31        26   \n",
      "2             2     548        91             29      34        25   \n",
      "3             3     548        82             31      11        24   \n",
      "4             4     548       105             32      19        23   \n",
      "...         ...     ...       ...            ...     ...       ...   \n",
      "4077       4077     819        21             22      23         4   \n",
      "4078       4078     819        16              8      14         3   \n",
      "4079       4079     819        19              8      15         2   \n",
      "4080       4080     819         0              0       1         1   \n",
      "4081       4081     819        66              4      12        10   \n",
      "\n",
      "                    date  \n",
      "0    1994-03-26 00:00:00  \n",
      "1    1994-03-26 00:00:00  \n",
      "2    1994-03-26 00:00:00  \n",
      "3    1994-03-26 00:00:00  \n",
      "4    1994-03-26 00:00:00  \n",
      "...                  ...  \n",
      "4077 2009-10-31 11:00:00  \n",
      "4078 2009-10-31 11:00:00  \n",
      "4079 2009-10-31 11:00:00  \n",
      "4080 2009-10-31 11:00:00  \n",
      "4081 2009-10-31 11:00:00  \n",
      "\n",
      "[4082 rows x 7 columns]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for table_name in db.table_dict.keys():\n",
    "    print(table_name)\n",
    "    print(db.table_dict[table_name].df)\n",
    "    df_ = db.table_dict[table_name].df\n",
    "    nan_columns = df_.columns[df_.isna().any()].tolist()\n",
    "    print(nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultId</th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>position</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>laps</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>fastestLap</th>\n",
       "      <th>rank</th>\n",
       "      <th>statusId</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18109</th>\n",
       "      <td>18109</td>\n",
       "      <td>713</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18110</th>\n",
       "      <td>18110</td>\n",
       "      <td>713</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18111</th>\n",
       "      <td>18111</td>\n",
       "      <td>713</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18112</th>\n",
       "      <td>18112</td>\n",
       "      <td>713</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18113</th>\n",
       "      <td>18113</td>\n",
       "      <td>713</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>62</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20318</th>\n",
       "      <td>20318</td>\n",
       "      <td>819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5669667.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20319</th>\n",
       "      <td>20319</td>\n",
       "      <td>819</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5666149.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20320</th>\n",
       "      <td>20320</td>\n",
       "      <td>819</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5661881.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20321</th>\n",
       "      <td>20321</td>\n",
       "      <td>819</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5661271.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20322</th>\n",
       "      <td>20322</td>\n",
       "      <td>819</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5689355.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2101 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       resultId  raceId  driverId  constructorId  number  grid  position  \\\n",
       "18109     18109     713        43              6    17.0    18      13.0   \n",
       "18110     18110     713        44             16    19.0    16      14.0   \n",
       "18111     18111     713        12             14    12.0    11       NaN   \n",
       "18112     18112     713        42              6    16.0    13      12.0   \n",
       "18113     18113     713        45             17    20.0    20       NaN   \n",
       "...         ...     ...       ...            ...     ...   ...       ...   \n",
       "20318     20318     819         1              1     6.0     8       5.0   \n",
       "20319     20319     819        21             22    23.0     4       4.0   \n",
       "20320     20320     819        17             22    22.0     5       3.0   \n",
       "20321     20321     819        16              8    14.0     3       2.0   \n",
       "20322     20322     819         2              2    16.0     9       9.0   \n",
       "\n",
       "       positionOrder  points  laps  milliseconds  fastestLap  rank  statusId  \\\n",
       "18109             13     0.0    56           NaN        35.0  14.0        12   \n",
       "18110             14     0.0    55           NaN        15.0  18.0        13   \n",
       "18111             15     0.0    44           NaN        11.0  12.0         5   \n",
       "18112             12     0.0    56           NaN        41.0  15.0        12   \n",
       "18113             17     0.0    43           NaN        10.0  19.0        62   \n",
       "...              ...     ...   ...           ...         ...   ...       ...   \n",
       "20318              5     4.0    55     5669667.0        54.0   7.0         1   \n",
       "20319              4     5.0    55     5666149.0        54.0   4.0         1   \n",
       "20320              3     6.0    55     5661881.0        49.0   6.0         1   \n",
       "20321              2     8.0    55     5661271.0        14.0   5.0         1   \n",
       "20322              9     0.0    55     5689355.0        49.0  15.0         1   \n",
       "\n",
       "                     date  \n",
       "18109 2004-03-07 00:00:00  \n",
       "18110 2004-03-07 00:00:00  \n",
       "18111 2004-03-07 00:00:00  \n",
       "18112 2004-03-07 00:00:00  \n",
       "18113 2004-03-07 00:00:00  \n",
       "...                   ...  \n",
       "20318 2009-11-01 11:00:00  \n",
       "20319 2009-11-01 11:00:00  \n",
       "20320 2009-11-01 11:00:00  \n",
       "20321 2009-11-01 11:00:00  \n",
       "20322 2009-11-01 11:00:00  \n",
       "\n",
       "[2101 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = db.table_dict[\"results\"].df\n",
    "table[~table[\"fastestLap\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sm3uYXqXkbZt"
   },
   "source": [
    "If trying a new dataset, you should definitely check through this dict of `stype`s to check that look right, and manually change any mistakes by the auto-detection function.\n",
    "\n",
    "Next we also define our text encoding model, which we use GloVe embeddings for speed and convenience. Feel free to try alternatives here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQHYmgIxkX1j",
    "outputId": "2bb3bdd4-6547-4575-8740-af68c44b0450"
   },
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers # we need another package for text encoding\n",
    "from typing import List, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device\n",
    "                                       ] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "L-BBpUrakdwY",
    "outputId": "fb150ef3-c1b2-4c11-8167-28bcc789d6b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from relbench.modeling.graph import make_pkey_fkey_graph\n",
    "\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
    ")\n",
    "\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
    "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
    "    cache_dir=os.path.join(\n",
    "        root_dir, f\"rel-f1_materialized_cache\"\n",
    "    ),  # store materialized graph for convenience\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwQejmg0kzOg"
   },
   "source": [
    "We can now check out `data`, our main graph object. `data` is a heterogeneous and temporal graph, with node types given by the table it originates from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd6DqCXgk41x"
   },
   "source": [
    "We can also check out the TensorFrame for one table like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  constructors={ tf=TensorFrame([211, 3]) },\n",
       "  circuits={ tf=TensorFrame([77, 7]) },\n",
       "  races={\n",
       "    tf=TensorFrame([820, 5]),\n",
       "    time=[820],\n",
       "  },\n",
       "  drivers={ tf=TensorFrame([857, 6]) },\n",
       "  constructor_standings={\n",
       "    tf=TensorFrame([10170, 4]),\n",
       "    time=[10170],\n",
       "  },\n",
       "  standings={\n",
       "    tf=TensorFrame([28115, 4]),\n",
       "    time=[28115],\n",
       "  },\n",
       "  constructor_results={\n",
       "    tf=TensorFrame([9408, 2]),\n",
       "    time=[9408],\n",
       "  },\n",
       "  results={\n",
       "    tf=TensorFrame([20323, 11]),\n",
       "    time=[20323],\n",
       "  },\n",
       "  qualifying={\n",
       "    tf=TensorFrame([4082, 3]),\n",
       "    time=[4082],\n",
       "  },\n",
       "  (races, f2p_circuitId, circuits)={ edge_index=[2, 820] },\n",
       "  (circuits, rev_f2p_circuitId, races)={ edge_index=[2, 820] },\n",
       "  (constructor_standings, f2p_raceId, races)={ edge_index=[2, 10170] },\n",
       "  (races, rev_f2p_raceId, constructor_standings)={ edge_index=[2, 10170] },\n",
       "  (constructor_standings, f2p_constructorId, constructors)={ edge_index=[2, 10170] },\n",
       "  (constructors, rev_f2p_constructorId, constructor_standings)={ edge_index=[2, 10170] },\n",
       "  (standings, f2p_raceId, races)={ edge_index=[2, 28115] },\n",
       "  (races, rev_f2p_raceId, standings)={ edge_index=[2, 28115] },\n",
       "  (standings, f2p_driverId, drivers)={ edge_index=[2, 28115] },\n",
       "  (drivers, rev_f2p_driverId, standings)={ edge_index=[2, 28115] },\n",
       "  (constructor_results, f2p_raceId, races)={ edge_index=[2, 9408] },\n",
       "  (races, rev_f2p_raceId, constructor_results)={ edge_index=[2, 9408] },\n",
       "  (constructor_results, f2p_constructorId, constructors)={ edge_index=[2, 9408] },\n",
       "  (constructors, rev_f2p_constructorId, constructor_results)={ edge_index=[2, 9408] },\n",
       "  (results, f2p_raceId, races)={ edge_index=[2, 20323] },\n",
       "  (races, rev_f2p_raceId, results)={ edge_index=[2, 20323] },\n",
       "  (results, f2p_driverId, drivers)={ edge_index=[2, 20323] },\n",
       "  (drivers, rev_f2p_driverId, results)={ edge_index=[2, 20323] },\n",
       "  (results, f2p_constructorId, constructors)={ edge_index=[2, 20323] },\n",
       "  (constructors, rev_f2p_constructorId, results)={ edge_index=[2, 20323] },\n",
       "  (qualifying, f2p_raceId, races)={ edge_index=[2, 4082] },\n",
       "  (races, rev_f2p_raceId, qualifying)={ edge_index=[2, 4082] },\n",
       "  (qualifying, f2p_driverId, drivers)={ edge_index=[2, 4082] },\n",
       "  (drivers, rev_f2p_driverId, qualifying)={ edge_index=[2, 4082] },\n",
       "  (qualifying, f2p_constructorId, constructors)={ edge_index=[2, 4082] },\n",
       "  (constructors, rev_f2p_constructorId, qualifying)={ edge_index=[2, 4082] }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "-mMQTQeLk1rl",
    "outputId": "ad625923-623b-4d3d-8fe3-3de2cbf584c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=5,\n",
       "  num_rows=820,\n",
       "  categorical (1): ['year'],\n",
       "  numerical (1): ['round'],\n",
       "  timestamp (2): ['date', 'time'],\n",
       "  embedding (1): ['name'],\n",
       "  has_target=False,\n",
       "  device='cpu',\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"races\"].tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kbysKXMk-3X"
   },
   "source": [
    "This may be a little confusing at first, as in graph ML it is more standard to associate to the graph object `data` a tensor, e.g., `data.x` for which `data.x[idx]` is a 1D array/tensor storing all the features for node with index `idx`.\n",
    "\n",
    "But actually this `data` object behaves similarly. For a given node type, e.g., `races` again, `data['races']` stores two pieces of information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDIcp7L5k6pU",
    "outputId": "be742ecb-02db-43e6-9c12-53fb00e51fec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf', 'time']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data[\"races\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z18qPRPllB1H"
   },
   "source": [
    "A `TensorFrame` object, and a timestamp for each node. The `TensorFrame` object acts analogously to the usual tensor of node features, and you can simply use indexing to retrieve the features of a single row (node), or group of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Im8bhNh5lFG6",
    "outputId": "7ae1e0bd-746a-4164-fc95-124e302c816d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=5,\n",
       "  num_rows=1,\n",
       "  categorical (1): ['year'],\n",
       "  numerical (1): ['round'],\n",
       "  timestamp (2): ['date', 'time'],\n",
       "  embedding (1): ['name'],\n",
       "  has_target=False,\n",
       "  device='cpu',\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"races\"].tf[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYZ28pzNlG4s",
    "outputId": "1066a167-2e3b-4ad6-d929-02acf18cad0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=5,\n",
       "  num_rows=10,\n",
       "  categorical (1): ['year'],\n",
       "  numerical (1): ['round'],\n",
       "  timestamp (2): ['date', 'time'],\n",
       "  embedding (1): ['name'],\n",
       "  has_target=False,\n",
       "  device='cpu',\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"races\"].tf[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql15svcelK3A"
   },
   "source": [
    "We can also check the edge indices between two different node types, such as `races` amd `circuits`. Note that the edges are also heterogenous, so we also need to specify which edge type we want to look at. Here we look at `f2p_curcuitId`, which are the directed edges pointing _from_ a race (the `f` stands for `foreign key`), _to_ the circuit at which te race happened (the `p` stands for `primary key`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TynkD36QlInL",
    "outputId": "abc2f80d-5ff4-42b1-f9e3-bd9f004d84ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[  0,   1,   2,  ..., 817, 818, 819],\n",
       "        [  8,   5,  18,  ...,  21,  17,  23]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(\"races\", \"f2p_circuitId\", \"circuits\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx4V5KCelNxl"
   },
   "source": [
    "Now we are ready to instantiate our data loaders. For this we will need to import PyTorch Geometric, our GNN library. Whilst we're at it let's add a seed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"depth\": 2,\n",
    "    \"num_sampled_neighbors\": 128,\n",
    "    \"batch_size\": 512,\n",
    "    \"temporal_strategy\": \"uniform\",\n",
    "    \"num_layers\": 2,\n",
    "    \"channels\": 128,    \n",
    "    \"aggr\":\"sum\",\n",
    "    \"id_awareness\": False,\n",
    "    \"num_blocks\": 1,\n",
    "    \"lr\": 0.005,\n",
    "    \"epochs\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-12-01 16:35:26.892232'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "str(pd.Timestamp.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\t\n",
    "\n",
    "# # reset the results file\n",
    "# cols = [\"id\", \"model\", \"val/test\", \"r2\", \"mae\", \"rmse\", \"date\", \"time\", \"where\", \"time_needed\", \"id_awareness\", \"epochs\", \"num_blocks\", \"num_sampled_neighbors\", \"depth\", \"batch_size\", \"temporal_strategy\", \"num_layers\", \"channels\", \"aggr\"]\n",
    "# df = pd.DataFrame(columns=cols)\n",
    "\n",
    "# df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_record(settings, val_test, errors, time_needed, where =\"Leila laptop\", which_model=\"Given model\", file = \"results.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    d = {}\n",
    "    for setting in settings:\n",
    "        d[setting] = settings[setting]\n",
    "    d[\"id\"] = None\n",
    "    d[\"model\"] = which_model\n",
    "    d[\"val/test\"] = val_test\n",
    "    d[\"where\"] = where\n",
    "    d[\"time_needed\"] = time_needed\n",
    "    \n",
    "    current_date = pd.Timestamp.now().strftime(\"%d.%m.%Y\")\n",
    "    current_time = pd.Timestamp.now().strftime(\"%H:%M:%S\")\n",
    "    d[\"date\"] = current_date\n",
    "    d[\"time\"] = current_time\n",
    "    \n",
    "\n",
    "    d[\"r2\"] = errors[\"r2\"]\n",
    "    d[\"mae\"] = errors[\"mae\"]\n",
    "    d[\"rmse\"] = errors[\"rmse\"]\n",
    "    \n",
    "    print(d)\n",
    "    \n",
    "\n",
    "    df2 = pd.DataFrame([d])\n",
    "\n",
    "    df3 = pd.concat([df, df2], ignore_index=True,axis=0)\n",
    "    \n",
    "    df3.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_record(settings, \"val\", (0.0, 0.0, 0.0), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HUHVG-g6lM-b"
   },
   "outputs": [],
   "source": [
    "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "loader_dict = {}\n",
    "\n",
    "for split, table in [\n",
    "    (\"train\", train_table),\n",
    "    (\"val\", val_table),\n",
    "    (\"test\", test_table),\n",
    "]:\n",
    "    table_input = get_node_train_table_input(\n",
    "        table=table,\n",
    "        task=task,\n",
    "    )\n",
    "    entity_table = table_input.nodes[0]\n",
    "    \n",
    "    depth = settings[\"depth\"]\n",
    "    num_sampled_neighbors = settings[\"num_sampled_neighbors\"]\n",
    "    \n",
    "    loader_dict[split] = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=[\n",
    "            num_sampled_neighbors for i in range(depth)\n",
    "            # 128 for i in range(2)\n",
    "            # 64 for i in range(2)\n",
    "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
    "        time_attr=\"time\",\n",
    "        input_nodes=table_input.nodes,\n",
    "        input_time=table_input.time,\n",
    "        transform=table_input.transform,\n",
    "        \n",
    "        batch_size=settings[\"batch_size\"],\n",
    "        \n",
    "        temporal_strategy=settings[\"temporal_strategy\"],\n",
    "        # If set to :obj:`\"uniform\"`, will sample uniformly across neighbors\n",
    "        #     that fulfill temporal constraints.\n",
    "        #     If set to :obj:`\"last\"`, will sample the last `num_neighbors` that\n",
    "        #     fulfill temporal constraints.\n",
    "        \n",
    "        shuffle=split == \"train\",\n",
    "        num_workers=0,\n",
    "        persistent_workers=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n"
     ]
    }
   ],
   "source": [
    "from modules import Model\n",
    "model = Model(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=settings[\"num_layers\"],\n",
    "    channels=settings[\"channels\"], # dim embeddingov (vmes), neodvisno\n",
    "    out_channels=1,\n",
    "    aggr=settings[\"aggr\"],\n",
    "    norm=\"batch_norm\",\n",
    "    id_awareness=settings[\"id_awareness\"],\n",
    "    \n",
    "    num_blocks=settings[\"num_blocks\"],\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# if you try out different RelBench tasks you will need to change these\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=settings[\"lr\"])\n",
    "epochs = settings[\"epochs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SAHRIr15lVs6"
   },
   "outputs": [],
   "source": [
    "def train() -> float:\n",
    "    model.train()\n",
    "\n",
    "    loss_accum = count_accum = 0\n",
    "    for batch in tqdm(loader_dict[\"train\"]):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(\n",
    "            batch,\n",
    "            task.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "\n",
    "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_accum += loss.detach().item() * pred.size(0)\n",
    "        count_accum += pred.size(0)\n",
    "\n",
    "    return loss_accum / count_accum\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: NeighborLoader) -> np.ndarray:\n",
    "    model.eval()\n",
    "\n",
    "    pred_list = []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(\n",
    "            batch,\n",
    "            task.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        pred_list.append(pred.detach().cpu())\n",
    "    return torch.cat(pred_list, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yF3W68Eqlew_",
    "outputId": "a81a48dc-234a-47f3-8759-8dc9a766661c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:07<00:00,  1.97it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 9.156819073894464, Val metrics: {'r2': -0.25962562852293347, 'mae': np.float64(4.378976262563376), 'rmse': np.float64(5.203206160374467)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.19it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 5.910387778848381, Val metrics: {'r2': -0.35911031835358376, 'mae': np.float64(4.313459126759786), 'rmse': np.float64(5.40477531612068)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.16it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 5.536874110916549, Val metrics: {'r2': 0.04265726883699761, 'mae': np.float64(3.733665740752746), 'rmse': np.float64(4.536114534260959)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:07<00:00,  2.13it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 5.422868694984623, Val metrics: {'r2': 0.042929615126980014, 'mae': np.float64(3.712322715575805), 'rmse': np.float64(4.535469268047352)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.19it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 5.383516694497185, Val metrics: {'r2': 0.08148292384405709, 'mae': np.float64(3.621194399908215), 'rmse': np.float64(4.443179994303242)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.17it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 5.110420102995065, Val metrics: {'r2': 0.22500828419271424, 'mae': np.float64(3.251774038341576), 'rmse': np.float64(4.08130282423043)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.16it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 4.9104123482780295, Val metrics: {'r2': 0.21226868486899586, 'mae': np.float64(3.3471568376443033), 'rmse': np.float64(4.114711069271802)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:07<00:00,  2.02it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 4.8489622215000745, Val metrics: {'r2': 0.20239523716787156, 'mae': np.float64(3.383254606722193), 'rmse': np.float64(4.1404177234994854)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:07<00:00,  1.90it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 4.809298372582175, Val metrics: {'r2': 0.21195805194790296, 'mae': np.float64(3.3996725256951073), 'rmse': np.float64(4.115522284156716)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.18it/s]\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 4.710041563670523, Val metrics: {'r2': 0.13200326333510737, 'mae': np.float64(3.5939535169021717), 'rmse': np.float64(4.31925988484657)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Val metrics: {'r2': 0.2252627401407451, 'mae': np.float64(3.2511641674385756), 'rmse': np.float64(4.080632754462731)}\n",
      "Best test metrics: {'r2': -0.06333044494035711, 'mae': np.float64(4.417801835578785), 'rmse': np.float64(5.372840895936277)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "state_dict = None\n",
    "best_val_metric = -math.inf if higher_is_better else math.inf\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train()\n",
    "    val_pred = test(loader_dict[\"val\"])\n",
    "    val_metrics = task.evaluate(val_pred, val_table)\n",
    "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
    "\n",
    "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
    "        not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
    "    ):\n",
    "        best_val_metric = val_metrics[tune_metric]\n",
    "        state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "time_needed = time.time() - start_time\n",
    "\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "val_pred = test(loader_dict[\"val\"])\n",
    "val_metrics = task.evaluate(val_pred, val_table)\n",
    "print(f\"Best Val metrics: {val_metrics}\")\n",
    "\n",
    "test_pred = test(loader_dict[\"test\"])\n",
    "test_metrics = task.evaluate(test_pred)\n",
    "print(f\"Best test metrics: {test_metrics}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 2, 'num_sampled_neighbors': 128, 'batch_size': 512, 'temporal_strategy': 'uniform', 'num_layers': 2, 'channels': 128, 'aggr': 'sum', 'id_awareness': False, 'num_blocks': 1, 'lr': 0.005, 'epochs': 10, 'id': None, 'model': 'Given model', 'val/test': 'val', 'where': 'Leila laptop', 'time_needed': 76.8809130191803, 'date': '01.12.2024', 'time': '16:36:45', 'r2': 0.2252627401407451, 'mae': np.float64(3.2511641674385756), 'rmse': np.float64(4.080632754462731)}\n",
      "{'depth': 2, 'num_sampled_neighbors': 128, 'batch_size': 512, 'temporal_strategy': 'uniform', 'num_layers': 2, 'channels': 128, 'aggr': 'sum', 'id_awareness': False, 'num_blocks': 1, 'lr': 0.005, 'epochs': 10, 'id': None, 'model': 'Given model', 'val/test': 'test', 'where': 'Leila laptop', 'time_needed': 76.8809130191803, 'date': '01.12.2024', 'time': '16:36:45', 'r2': -0.06333044494035711, 'mae': np.float64(4.417801835578785), 'rmse': np.float64(5.372840895936277)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33199/2010031029.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df3 = pd.concat([df, df2], ignore_index=True,axis=0)\n"
     ]
    }
   ],
   "source": [
    "new_record(settings, \"val\", val_metrics, time_needed)\n",
    "new_record(settings, \"test\", test_metrics, time_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"metrics.out\", \"a\") as f:\n",
    "#     f.write(f\"Best Val metrics: {list(map(float, val_metrics.values()))}\\n\".replace(\",\",\"\"))\n",
    "#     f.write(f\"Best test metrics: {list(map(float, test_metrics.values()))}\\n\".replace(\",\",\"\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q68ijOgNbCUr",
        "outputId": "f8a0e542-2ea0-4a72-fc9e-0d7f50c7c185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cpu.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt25cpu)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt25cpu)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt25cpu)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt25cpu)\n",
            "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.10/dist-packages (0.4.0+pt25cpu)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: pytorch_frame in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (2.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (4.66.6)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (17.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pytorch_frame) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pytorch_frame) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pytorch_frame) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->pytorch_frame) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->pytorch_frame) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_frame) (3.0.2)\n",
            "Requirement already satisfied: relbench in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from relbench) (2.2.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from relbench) (1.8.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from relbench) (17.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from relbench) (1.26.4)\n",
            "Requirement already satisfied: duckdb in /usr/local/lib/python3.10/dist-packages (from relbench) (1.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from relbench) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from relbench) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->relbench) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->relbench) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->relbench) (2024.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->relbench) (4.3.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->relbench) (24.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch->relbench) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->relbench) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->relbench) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->relbench) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->relbench) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->relbench) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->relbench) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->relbench) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->relbench) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "\n",
        "\n",
        "!pip install torch==2.5.0\n",
        "!pip install torch-geometric torch-sparse torch-scatter torch-cluster torch-spline-conv pyg-lib -f https://data.pyg.org/whl/torch-2.5.0+cpu.html\n",
        "!pip install pytorch_frame\n",
        "!pip install relbench"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "\n",
        "relbench.__version__"
      ],
      "metadata": {
        "id": "6naioDspjnUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9b22b99c-e660-45c5-ca00-67b1bab2830f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lbboFKCRjlBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.tasks import get_task\n",
        "\n",
        "dataset = get_dataset(\"rel-f1\", download=True)\n",
        "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
        "\n",
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")\n",
        "\n",
        "out_channels = 1\n",
        "loss_fn = L1Loss()\n",
        "tune_metric = \"mae\"\n",
        "higher_is_better = False"
      ],
      "metadata": {
        "id": "Slo7ebllbMY7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch_frame\n",
        "\n",
        "# Some book keeping\n",
        "from torch_geometric.seed import seed_everything\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)  # check that it's cuda if you want it to run in reasonable time!\n",
        "root_dir = \"./data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNd8X2bBdKHi",
        "outputId": "5a240ac0-eed3-41f6-fec5-112ef0b9113a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kEvzCeZh0EPU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.modeling.utils import get_stype_proposal\n",
        "\n",
        "db = dataset.get_db()\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "col_to_stype_dict\n",
        "\n",
        "db.min_timestamp, db.max_timestamp\n",
        "print(col_to_stype_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22H6T7IFew_1",
        "outputId": "c4a84076-8d20-4cf9-a3cf-ac71017d3953"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'standings': {'driverStandingsId': <stype.numerical: 'numerical'>, 'raceId': <stype.numerical: 'numerical'>, 'driverId': <stype.numerical: 'numerical'>, 'points': <stype.numerical: 'numerical'>, 'position': <stype.numerical: 'numerical'>, 'wins': <stype.numerical: 'numerical'>, 'date': <stype.timestamp: 'timestamp'>}, 'constructors': {'constructorId': <stype.numerical: 'numerical'>, 'constructorRef': <stype.text_embedded: 'text_embedded'>, 'name': <stype.text_embedded: 'text_embedded'>, 'nationality': <stype.text_embedded: 'text_embedded'>}, 'results': {'resultId': <stype.numerical: 'numerical'>, 'raceId': <stype.numerical: 'numerical'>, 'driverId': <stype.numerical: 'numerical'>, 'constructorId': <stype.numerical: 'numerical'>, 'number': <stype.numerical: 'numerical'>, 'grid': <stype.numerical: 'numerical'>, 'position': <stype.numerical: 'numerical'>, 'positionOrder': <stype.numerical: 'numerical'>, 'points': <stype.numerical: 'numerical'>, 'laps': <stype.numerical: 'numerical'>, 'milliseconds': <stype.numerical: 'numerical'>, 'fastestLap': <stype.numerical: 'numerical'>, 'rank': <stype.numerical: 'numerical'>, 'statusId': <stype.numerical: 'numerical'>, 'date': <stype.timestamp: 'timestamp'>}, 'drivers': {'driverId': <stype.numerical: 'numerical'>, 'driverRef': <stype.text_embedded: 'text_embedded'>, 'code': <stype.text_embedded: 'text_embedded'>, 'forename': <stype.text_embedded: 'text_embedded'>, 'surname': <stype.text_embedded: 'text_embedded'>, 'dob': <stype.timestamp: 'timestamp'>, 'nationality': <stype.text_embedded: 'text_embedded'>}, 'constructor_standings': {'constructorStandingsId': <stype.numerical: 'numerical'>, 'raceId': <stype.numerical: 'numerical'>, 'constructorId': <stype.numerical: 'numerical'>, 'points': <stype.numerical: 'numerical'>, 'position': <stype.numerical: 'numerical'>, 'wins': <stype.numerical: 'numerical'>, 'date': <stype.timestamp: 'timestamp'>}, 'qualifying': {'qualifyId': <stype.numerical: 'numerical'>, 'raceId': <stype.numerical: 'numerical'>, 'driverId': <stype.numerical: 'numerical'>, 'constructorId': <stype.numerical: 'numerical'>, 'number': <stype.numerical: 'numerical'>, 'position': <stype.numerical: 'numerical'>, 'date': <stype.timestamp: 'timestamp'>}, 'constructor_results': {'constructorResultsId': <stype.numerical: 'numerical'>, 'raceId': <stype.numerical: 'numerical'>, 'constructorId': <stype.numerical: 'numerical'>, 'points': <stype.numerical: 'numerical'>, 'date': <stype.timestamp: 'timestamp'>}, 'circuits': {'circuitId': <stype.numerical: 'numerical'>, 'circuitRef': <stype.text_embedded: 'text_embedded'>, 'name': <stype.text_embedded: 'text_embedded'>, 'location': <stype.text_embedded: 'text_embedded'>, 'country': <stype.text_embedded: 'text_embedded'>, 'lat': <stype.numerical: 'numerical'>, 'lng': <stype.numerical: 'numerical'>, 'alt': <stype.numerical: 'numerical'>}, 'races': {'raceId': <stype.numerical: 'numerical'>, 'year': <stype.categorical: 'categorical'>, 'round': <stype.numerical: 'numerical'>, 'circuitId': <stype.numerical: 'numerical'>, 'name': <stype.text_embedded: 'text_embedded'>, 'date': <stype.timestamp: 'timestamp'>, 'time': <stype.timestamp: 'timestamp'>}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uGrSMtBooA7h"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers # we need another package for text encoding\n",
        "from typing import List, Optional\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class GloveTextEmbedding:\n",
        "    def __init__(self, device: Optional[torch.device\n",
        "                                       ] = None):\n",
        "        self.model = SentenceTransformer(\n",
        "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    def __call__(self, sentences: List[str]) -> Tensor:\n",
        "        return torch.from_numpy(self.model.encode(sentences))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz065p-Jez5d",
        "outputId": "002c5bf0-1f4a-46a6-8ddd-cbaa33477bca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Any, Dict, NamedTuple, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch_frame import stype\n",
        "from torch_frame.config import TextEmbedderConfig\n",
        "from torch_frame.data import Dataset\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.typing import NodeType\n",
        "from torch_geometric.utils import sort_edge_index\n",
        "\n",
        "from relbench.base import Database, EntityTask, RecommendationTask, Table, TaskType\n",
        "from relbench.modeling.utils import remove_pkey_fkey, to_unix_time\n",
        "\n",
        "\n",
        "def make_pkey_fkey_graph_implementation(\n",
        "    db: Database,\n",
        "    col_to_stype_dict: Dict[str, Dict[str, stype]],\n",
        "    text_embedder_cfg: Optional[TextEmbedderConfig] = None,\n",
        "    cache_dir: Optional[str] = None,\n",
        ") -> Tuple[HeteroData, Dict[str, Dict[str, Dict[StatType, Any]]]]:\n",
        "    r\"\"\"Given a :class:`Database` object, construct a heterogeneous graph with primary-\n",
        "    foreign key relationships, together with the column stats of each table.\n",
        "\n",
        "    Args:\n",
        "        db: A database object containing a set of tables.\n",
        "        col_to_stype_dict: Column to stype for\n",
        "            each table.\n",
        "        text_embedder_cfg: Text embedder config.\n",
        "        cache_dir: A directory for storing materialized tensor\n",
        "            frames. If specified, we will either cache the file or use the\n",
        "            cached file. If not specified, we will not use cached file and\n",
        "            re-process everything from scratch without saving the cache.\n",
        "\n",
        "    Returns:\n",
        "        HeteroData: The heterogeneous :class:`PyG` object with\n",
        "            :class:`TensorFrame` feature.\n",
        "    \"\"\"\n",
        "    data = HeteroData()\n",
        "    col_stats_dict = dict()\n",
        "    if cache_dir is not None:\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "    for table_name, table in db.table_dict.items():\n",
        "        # Materialize the tables into tensor frames:\n",
        "        df = table.df\n",
        "        # Ensure that pkey is consecutive.\n",
        "        if table.pkey_col is not None:\n",
        "            assert (df[table.pkey_col].values == np.arange(len(df))).all()\n",
        "\n",
        "        col_to_stype = col_to_stype_dict[table_name]\n",
        "\n",
        "        # Remove pkey, fkey columns since they will not be used as input\n",
        "        # feature.\n",
        "        remove_pkey_fkey(col_to_stype, table)\n",
        "\n",
        "        if len(col_to_stype) == 0:  # Add constant feature in case df is empty:\n",
        "            col_to_stype = {\"__const__\": stype.numerical}\n",
        "            # We need to add edges later, so we need to also keep the fkeys\n",
        "            fkey_dict = {key: df[key] for key in table.fkey_col_to_pkey_table}\n",
        "            df = pd.DataFrame({\"__const__\": np.ones(len(table.df)), **fkey_dict})\n",
        "\n",
        "        path = (\n",
        "            None if cache_dir is None else os.path.join(cache_dir, f\"{table_name}.pt\")\n",
        "        )\n",
        "\n",
        "        dataset = Dataset(\n",
        "            df=df,\n",
        "            col_to_stype=col_to_stype,\n",
        "            col_to_text_embedder_cfg=text_embedder_cfg,\n",
        "        ).materialize(path=path)\n",
        "\n",
        "        data[table_name].tf = dataset.tensor_frame\n",
        "        col_stats_dict[table_name] = dataset.col_stats\n",
        "\n",
        "        # Add time attribute:\n",
        "        if table.time_col is not None:\n",
        "            data[table_name].time = torch.from_numpy(\n",
        "                to_unix_time(table.df[table.time_col])\n",
        "            )\n",
        "\n",
        "        # Add edges:\n",
        "        for fkey_name, pkey_table_name in table.fkey_col_to_pkey_table.items():\n",
        "            pkey_index = df[fkey_name]\n",
        "            # Filter out dangling foreign keys\n",
        "            mask = ~pkey_index.isna()\n",
        "            fkey_index = torch.arange(len(pkey_index))\n",
        "            # Filter dangling foreign keys:\n",
        "            pkey_index = torch.from_numpy(pkey_index[mask].astype(int).values)\n",
        "            fkey_index = fkey_index[torch.from_numpy(mask.values)]\n",
        "            # Ensure no dangling fkeys\n",
        "            assert (pkey_index < len(db.table_dict[pkey_table_name])).all()\n",
        "\n",
        "            # fkey -> pkey edges\n",
        "            edge_index = torch.stack([fkey_index, pkey_index], dim=0)\n",
        "            edge_type = (table_name, f\"f2p_{fkey_name}\", pkey_table_name)\n",
        "            data[edge_type].edge_index = sort_edge_index(edge_index)\n",
        "\n",
        "            # pkey -> fkey edges.\n",
        "            # \"rev_\" is added so that PyG loader recognizes the reverse edges\n",
        "            edge_index = torch.stack([pkey_index, fkey_index], dim=0)\n",
        "            edge_type = (pkey_table_name, f\"rev_f2p_{fkey_name}\", table_name)\n",
        "            data[edge_type].edge_index = sort_edge_index(edge_index)\n",
        "\n",
        "    data.validate()\n",
        "\n",
        "    return data, col_stats_dict\n"
      ],
      "metadata": {
        "id": "T7byfWAqFDvM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "\n",
        "text_embedder_cfg = TextEmbedderConfig(\n",
        "    text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
        ")\n",
        "\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    db,\n",
        "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
        "    text_embedder_cfg=text_embedder_cfg,# our chosen text encoder\n",
        "    cache_dir=os.path.join(\n",
        "        root_dir, f\"rel-f1_materialized_cache\"\n",
        "    ),  # store materialized graph for convenience\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpIgzngXe1dy",
        "outputId": "2f18c1d2-fd9c-4433-96bc-278e64f0684f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c0TUjJcKe9Uv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "loader_dict = {}\n",
        "\n",
        "for split, table in [\n",
        "    (\"train\", train_table),\n",
        "    (\"val\", val_table),\n",
        "    (\"test\", test_table),\n",
        "]:\n",
        "    table_input = get_node_train_table_input(\n",
        "        table=table,\n",
        "        task=task,\n",
        "    )\n",
        "    entity_table = table_input.nodes[0]\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=[\n",
        "            128 for i in range(2)\n",
        "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.nodes,\n",
        "        input_time=table_input.time,\n",
        "        transform=table_input.transform,\n",
        "        batch_size=512,\n",
        "        temporal_strategy=\"uniform\",\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=0,\n",
        "        persistent_workers=False,\n",
        "    )"
      ],
      "metadata": {
        "id": "-WPizu-CgQER"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yhCubEi3zV7T"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_table"
      ],
      "metadata": {
        "id": "_xPTbZeGzU3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a9f6a9-c413-443f-a88c-12607c237435"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Table(df=\n",
              "           date  driverId  position\n",
              "0    2004-07-05        10     10.75\n",
              "1    2004-07-05        47     12.00\n",
              "2    2004-03-07         7     15.00\n",
              "3    2004-01-07        10      9.00\n",
              "4    2003-09-09        52     13.00\n",
              "...         ...       ...       ...\n",
              "7448 1995-08-22        96     15.75\n",
              "7449 1975-06-08       228      8.00\n",
              "7450 1965-05-31       418     16.00\n",
              "7451 1961-08-20       467     37.00\n",
              "7452 1954-05-29       677     30.00\n",
              "\n",
              "[7453 rows x 3 columns],\n",
              "  fkey_col_to_pkey_table={'driverId': 'drivers'},\n",
              "  pkey_col=None,\n",
              "  time_col=date)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ccFTbuPzWjU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UQRQ9546wqza"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1pWnUQFazayK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GraphConv\n",
        "from typing import Any, Dict, List, Optional\n",
        "from torch_frame.data.stats import StatType\n",
        "\n",
        "\n",
        "test_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwviiMQGx-Ah",
        "outputId": "58b77023-5022-4a7f-8d4c-1b827075c9fe"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Table(df=\n",
              "          date  driverId\n",
              "0   2016-05-29       835\n",
              "1   2016-03-30         3\n",
              "2   2016-03-30       807\n",
              "3   2016-03-30       831\n",
              "4   2016-01-30       830\n",
              "..         ...       ...\n",
              "755 2010-10-28        66\n",
              "756 2010-10-28        19\n",
              "757 2010-10-28         8\n",
              "758 2010-08-29         0\n",
              "759 2010-08-29        16\n",
              "\n",
              "[760 rows x 2 columns],\n",
              "  fkey_col_to_pkey_table={'driverId': 'drivers'},\n",
              "  pkey_col=None,\n",
              "  time_col=date)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "\n",
        "from relbench.modeling.nn import HeteroTemporalEncoder,HeteroEncoder\n",
        "from torch_geometric.nn import HeteroConv, LayerNorm, PositionalEncoding, SAGEConv\n",
        "\n",
        "import torch\n",
        "from torch_geometric.nn import HeteroConv, GATConv, LayerNorm\n",
        "from torch_geometric.typing import EdgeType, NodeType\n",
        "from torch_geometric.nn import RGCNConv, LayerNorm, HeteroConv\n",
        "from torch_frame.nn.models import ResNet"
      ],
      "metadata": {
        "id": "g_TKgJ3B2tHF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfyfmY_x6zLr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class HeteroGraphRGCN(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_types: List[NodeType],\n",
        "        edge_types: List[EdgeType],\n",
        "        num_relations: int,\n",
        "        channels: int,\n",
        "        aggr: str = \"mean\",\n",
        "        num_layers: int = 2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            conv = HeteroConv(\n",
        "                {\n",
        "                    edge_type: RGCNConv((channels, channels), channels, num_relations, aggr=aggr)\n",
        "                    for edge_type in edge_types\n",
        "                },\n",
        "                aggr=\"sum\",\n",
        "            )\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        self.norms = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            norm_dict = torch.nn.ModuleDict()\n",
        "            for node_type in node_types:\n",
        "                norm_dict[node_type] = LayerNorm(channels, mode=\"node\")\n",
        "            self.norms.append(norm_dict)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for norm_dict in self.norms:\n",
        "            for norm in norm_dict.values():\n",
        "                norm.reset_parameters()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x_dict: Dict[NodeType, Tensor],\n",
        "        edge_index_dict: Dict[NodeType, Tensor],\n",
        "        edge_type_dict: Dict[NodeType, Tensor],\n",
        "        num_sampled_nodes_dict: Optional[Dict[NodeType, List[int]]] = None,\n",
        "        num_sampled_edges_dict: Optional[Dict[EdgeType, List[int]]] = None,\n",
        "    ) -> Dict[NodeType, Tensor]:\n",
        "        for _, (conv, norm_dict) in enumerate(zip(self.convs, self.norms)):\n",
        "           # print(\"I am here pookie\")\n",
        "            x_dict = conv(x_dict, edge_index_dict,edge_type_dict)\n",
        "            x_dict = {key: norm_dict[key](x) for key, x in x_dict.items()}\n",
        "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
        "\n",
        "        return x_dict"
      ],
      "metadata": {
        "id": "wrDEVr349OKb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "\n",
        "from relbench.modeling.nn import HeteroTemporalEncoder\n",
        "\n",
        "from torch_sparse import SparseTensor\n",
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData,\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        # List of node types to add shallow embeddings to input\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        # ID awareness\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "        self.gnn = HeteroGraphRGCN(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            aggr=aggr,\n",
        "            num_layers=num_layers,\n",
        "            num_relations = len(data.edge_types)\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = rel_time + x_dict[node_type]\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        edge_type_tensor_dict = {}\n",
        "\n",
        "        for relation_idx, (relation, edge_index) in enumerate(batch.edge_index_dict.items()):\n",
        "            edge_type_tensor = torch.full((edge_index.size(1),), relation_idx, dtype=torch.long)\n",
        "            edge_type_tensor_dict[relation] = edge_type_tensor\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "        x_dict,\n",
        "        batch.edge_index_dict,\n",
        "        edge_type_tensor_dict,\n",
        "        )\n",
        "\n",
        "\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        # Add ID-awareness to the root node\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=2,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"sum\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# if you try out different RelBench tasks you will need to change these\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "zgWoOXplUu2V"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train() -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "\n",
        "\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ],
      "metadata": {
        "id": "jkNn0xLZwtqE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = None\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train()\n",
        "    val_pred = test(loader_dict[\"val\"])\n",
        "    val_metrics = task.evaluate(val_pred, val_table)\n",
        "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "        not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "val_pred = test(loader_dict[\"val\"])\n",
        "val_metrics = task.evaluate(val_pred, val_table)\n",
        "print(f\"Best Val metrics: {val_metrics}\")\n",
        "\n",
        "test_pred = test(loader_dict[\"test\"])\n",
        "test_metrics = task.evaluate(test_pred)\n",
        "print(f\"Best test metrics: {test_metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pWKxpYqUuvw",
        "outputId": "8ebe632b-d973-4a7a-a171-68485fdba314"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:18<00:00,  1.26s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Train loss: 9.171768554949558, Val metrics: {'r2': -0.2591827325431011, 'mae': 4.378419226937559, 'rmse': 5.202291332332261}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:09<00:00,  1.51it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02, Train loss: 5.927582364969728, Val metrics: {'r2': -0.3584292719734148, 'mae': 4.307743330390436, 'rmse': 5.403420987537844}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.41it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03, Train loss: 5.527325287259346, Val metrics: {'r2': 0.023231464821019898, 'mae': 3.7684723003593863, 'rmse': 4.58190541996098}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.43it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 04, Train loss: 5.407753329812545, Val metrics: {'r2': 0.0463471780426995, 'mae': 3.7293652419177548, 'rmse': 4.527364266637253}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:11<00:00,  1.36it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05, Train loss: 5.380794122717164, Val metrics: {'r2': 0.04084885760022128, 'mae': 3.68155843598411, 'rmse': 4.540396851324575}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.44it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 06, Train loss: 5.188616255697877, Val metrics: {'r2': 0.15357905430221008, 'mae': 3.3811845655829886, 'rmse': 4.265240168741499}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.41it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 07, Train loss: 4.899387038507414, Val metrics: {'r2': 0.21497551758697753, 'mae': 3.2813673011764495, 'rmse': 4.107635421222893}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:11<00:00,  1.33it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 08, Train loss: 4.843547212026686, Val metrics: {'r2': 0.2527865224495427, 'mae': 3.1933139565951363, 'rmse': 4.007491759301843}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.44it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 09, Train loss: 4.810740384642236, Val metrics: {'r2': 0.24487312605157274, 'mae': 3.170008482898006, 'rmse': 4.028656626749304}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.48it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Train loss: 4.7688987357143295, Val metrics: {'r2': 0.2430804097704058, 'mae': 3.17376629161134, 'rmse': 4.033435927519448}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Val metrics: {'r2': 0.24861332541660353, 'mae': 3.1618932104142567, 'rmse': 4.018667124300675}\n",
            "Best test metrics: {'r2': 0.06613019665857878, 'mae': 4.153747563236638, 'rmse': 5.0351570633286125}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T00:05:04.397024Z",
     "iopub.status.busy": "2024-07-26T00:05:04.396612Z",
     "iopub.status.idle": "2024-07-26T00:05:05.049064Z",
     "shell.execute_reply": "2024-07-26T00:05:05.048407Z",
     "shell.execute_reply.started": "2024-07-26T00:05:04.397003Z"
    },
    "id": "ZwlNp-76idJe",
    "outputId": "f6591f14-c93f-4df7-d8bb-d1d4a62b5330"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import relbench\n",
    "\n",
    "relbench.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6DWB-Kf6nl2y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "\n",
    "dataset = get_dataset(\"rel-f1\", download=True)\n",
    "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
    "\n",
    "train_table = task.get_table(\"train\")\n",
    "val_table = task.get_table(\"val\")\n",
    "test_table = task.get_table(\"test\")\n",
    "\n",
    "out_channels = 1\n",
    "loss_fn = L1Loss()\n",
    "tune_metric = \"mae\"\n",
    "higher_is_better = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKFT5H51j_Um"
   },
   "source": [
    "Let's check out the training table just to make sure it looks fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABN_fdN3kAB9",
    "outputId": "afb2d6b1-a54f-4b68-b6d1-5894ec7b3b87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table(df=\n",
       "           date  driverId  position\n",
       "0    2004-07-05        10     10.75\n",
       "1    2004-07-05        47     12.00\n",
       "2    2004-03-07         7     15.00\n",
       "3    2004-01-07        10      9.00\n",
       "4    2003-09-09        52     13.00\n",
       "...         ...       ...       ...\n",
       "7448 1995-08-22        96     15.75\n",
       "7449 1975-06-08       228      8.00\n",
       "7450 1965-05-31       418     16.00\n",
       "7451 1961-08-20       467     37.00\n",
       "7452 1954-05-29       677     30.00\n",
       "\n",
       "[7453 rows x 3 columns],\n",
       "  fkey_col_to_pkey_table={'driverId': 'drivers'},\n",
       "  pkey_col=None,\n",
       "  time_col=date)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQhuHIdHkOxv"
   },
   "source": [
    "Note that to load the data we did not require any deep learning libraries. Now we introduce the PyTorch Frame library, which is useful for encoding individual tables into initial node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNzfdwsrkPIo",
    "outputId": "0bb44a5f-ea16-40fe-db25-6868ac05ef99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_frame\n",
    "\n",
    "# Some book keeping\n",
    "from torch_geometric.seed import seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # check that it's cuda if you want it to run in reasonable time!\n",
    "root_dir = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Y79g5H0kVjX"
   },
   "source": [
    "The first big move is to build a graph out of the database. Here we use our pre-prepared conversion function.\n",
    "\n",
    "The source code can be found at: https://github.com/snap-stanford/relbench/blob/main/relbench/modeling/graph.py\n",
    "\n",
    "Each node in the graph corresonds to a single row in the database. Crucially, PyTorch Frame stores whole tables as objects in a way that is compatibile with PyG minibatch sampling, meaning we can sample subgraphs as in https://arxiv.org/abs/1706.02216, and retrieve the relevant raw features.\n",
    "\n",
    "PyTorch Frame also stores the `stype` (i.e., modality) of each column, and any specialized feature encoders (e.g., text encoders) to be used later. So we need to configure the `stype` for each column, for which we use a function that tries to automatically detect the `stype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kiV3TGI-kRuy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lema/.cache/relbench/rel-f1/db...\n",
      "Done in 0.04 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'constructors': {'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'constructorRef': <stype.text_embedded: 'text_embedded'>,\n",
       "  'name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'nationality': <stype.text_embedded: 'text_embedded'>},\n",
       " 'circuits': {'circuitId': <stype.numerical: 'numerical'>,\n",
       "  'circuitRef': <stype.text_embedded: 'text_embedded'>,\n",
       "  'name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'location': <stype.text_embedded: 'text_embedded'>,\n",
       "  'country': <stype.text_embedded: 'text_embedded'>,\n",
       "  'lat': <stype.numerical: 'numerical'>,\n",
       "  'lng': <stype.numerical: 'numerical'>,\n",
       "  'alt': <stype.numerical: 'numerical'>},\n",
       " 'races': {'raceId': <stype.numerical: 'numerical'>,\n",
       "  'year': <stype.categorical: 'categorical'>,\n",
       "  'round': <stype.numerical: 'numerical'>,\n",
       "  'circuitId': <stype.numerical: 'numerical'>,\n",
       "  'name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>,\n",
       "  'time': <stype.timestamp: 'timestamp'>},\n",
       " 'drivers': {'driverId': <stype.numerical: 'numerical'>,\n",
       "  'driverRef': <stype.text_embedded: 'text_embedded'>,\n",
       "  'code': <stype.text_embedded: 'text_embedded'>,\n",
       "  'forename': <stype.text_embedded: 'text_embedded'>,\n",
       "  'surname': <stype.text_embedded: 'text_embedded'>,\n",
       "  'dob': <stype.timestamp: 'timestamp'>,\n",
       "  'nationality': <stype.text_embedded: 'text_embedded'>},\n",
       " 'constructor_standings': {'constructorStandingsId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'wins': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'standings': {'driverStandingsId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'driverId': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'wins': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'constructor_results': {'constructorResultsId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'results': {'resultId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'driverId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'number': <stype.numerical: 'numerical'>,\n",
       "  'grid': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'positionOrder': <stype.numerical: 'numerical'>,\n",
       "  'points': <stype.numerical: 'numerical'>,\n",
       "  'laps': <stype.numerical: 'numerical'>,\n",
       "  'milliseconds': <stype.numerical: 'numerical'>,\n",
       "  'fastestLap': <stype.numerical: 'numerical'>,\n",
       "  'rank': <stype.numerical: 'numerical'>,\n",
       "  'statusId': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>},\n",
       " 'qualifying': {'qualifyId': <stype.numerical: 'numerical'>,\n",
       "  'raceId': <stype.numerical: 'numerical'>,\n",
       "  'driverId': <stype.numerical: 'numerical'>,\n",
       "  'constructorId': <stype.numerical: 'numerical'>,\n",
       "  'number': <stype.numerical: 'numerical'>,\n",
       "  'position': <stype.numerical: 'numerical'>,\n",
       "  'date': <stype.timestamp: 'timestamp'>}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from relbench.modeling.utils import get_stype_proposal\n",
    "\n",
    "db = dataset.get_db()\n",
    "col_to_stype_dict = get_stype_proposal(db)\n",
    "col_to_stype_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPK7hYz_fTJo",
    "outputId": "36491c17-4ef1-494c-fa86-1266884cee5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['constructors', 'circuits', 'races', 'drivers', 'constructor_standings', 'standings', 'constructor_results', 'results', 'qualifying'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.table_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "taqsrgZ0fiPs",
    "outputId": "6033c45e-3307-45be-e37c-eab207dccd30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circuitId</th>\n",
       "      <th>circuitRef</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>albert_park</td>\n",
       "      <td>Albert Park Grand Prix Circuit</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Australia</td>\n",
       "      <td>-37.84970</td>\n",
       "      <td>144.96800</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sepang</td>\n",
       "      <td>Sepang International Circuit</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2.76083</td>\n",
       "      <td>101.73800</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bahrain</td>\n",
       "      <td>Bahrain International Circuit</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>26.03250</td>\n",
       "      <td>50.51060</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>catalunya</td>\n",
       "      <td>Circuit de Barcelona-Catalunya</td>\n",
       "      <td>Montmeló</td>\n",
       "      <td>Spain</td>\n",
       "      <td>41.57000</td>\n",
       "      <td>2.26111</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>Istanbul Park</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.95170</td>\n",
       "      <td>29.40500</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>portimao</td>\n",
       "      <td>Autódromo Internacional do Algarve</td>\n",
       "      <td>Portimão</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>37.22700</td>\n",
       "      <td>-8.62670</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>mugello</td>\n",
       "      <td>Autodromo Internazionale del Mugello</td>\n",
       "      <td>Mugello</td>\n",
       "      <td>Italy</td>\n",
       "      <td>43.99750</td>\n",
       "      <td>11.37190</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>jeddah</td>\n",
       "      <td>Jeddah Corniche Circuit</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>21.63190</td>\n",
       "      <td>39.10440</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>losail</td>\n",
       "      <td>Losail International Circuit</td>\n",
       "      <td>Al Daayen</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>25.49000</td>\n",
       "      <td>51.45420</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>miami</td>\n",
       "      <td>Miami International Autodrome</td>\n",
       "      <td>Miami</td>\n",
       "      <td>USA</td>\n",
       "      <td>25.95810</td>\n",
       "      <td>-80.23890</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    circuitId   circuitRef                                  name  \\\n",
       "0           0  albert_park        Albert Park Grand Prix Circuit   \n",
       "1           1       sepang          Sepang International Circuit   \n",
       "2           2      bahrain         Bahrain International Circuit   \n",
       "3           3    catalunya        Circuit de Barcelona-Catalunya   \n",
       "4           4     istanbul                         Istanbul Park   \n",
       "..        ...          ...                                   ...   \n",
       "72         72     portimao    Autódromo Internacional do Algarve   \n",
       "73         73      mugello  Autodromo Internazionale del Mugello   \n",
       "74         74       jeddah               Jeddah Corniche Circuit   \n",
       "75         75       losail          Losail International Circuit   \n",
       "76         76        miami         Miami International Autodrome   \n",
       "\n",
       "        location       country       lat        lng    alt  \n",
       "0      Melbourne     Australia -37.84970  144.96800   10.0  \n",
       "1   Kuala Lumpur      Malaysia   2.76083  101.73800   18.0  \n",
       "2         Sakhir       Bahrain  26.03250   50.51060    7.0  \n",
       "3       Montmeló         Spain  41.57000    2.26111  109.0  \n",
       "4       Istanbul        Turkey  40.95170   29.40500  130.0  \n",
       "..           ...           ...       ...        ...    ...  \n",
       "72      Portimão      Portugal  37.22700   -8.62670  108.0  \n",
       "73       Mugello         Italy  43.99750   11.37190  255.0  \n",
       "74        Jeddah  Saudi Arabia  21.63190   39.10440   15.0  \n",
       "75     Al Daayen         Qatar  25.49000   51.45420   15.0  \n",
       "76         Miami           USA  25.95810  -80.23890    2.0  \n",
       "\n",
       "[77 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = db.table_dict[\"circuits\"].df\n",
    "# table[table[\"alt\"].isnull()]\n",
    "table\n",
    "# set missing alt\n",
    "table.loc[75, \"alt\"] = 15\n",
    "table.loc[76, \"alt\"] = 2\n",
    "table.loc[22, \"alt\"] = 634\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Bz0lobfxFh",
    "outputId": "9f129fb9-4ff8-4bda-c837-e1cc8b53bad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructors\n",
      "     constructorId constructorRef            name nationality\n",
      "0                0        mclaren         McLaren     British\n",
      "1                1     bmw_sauber      BMW Sauber      German\n",
      "2                2       williams        Williams     British\n",
      "3                3        renault         Renault      French\n",
      "4                4     toro_rosso      Toro Rosso     Italian\n",
      "..             ...            ...             ...         ...\n",
      "206            206          manor  Manor Marussia     British\n",
      "207            207           haas    Haas F1 Team    American\n",
      "208            208   racing_point    Racing Point     British\n",
      "209            209     alphatauri      AlphaTauri     Italian\n",
      "210            210         alpine  Alpine F1 Team      French\n",
      "\n",
      "[211 rows x 4 columns]\n",
      "[]\n",
      "circuits\n",
      "    circuitId   circuitRef                                  name  \\\n",
      "0           0  albert_park        Albert Park Grand Prix Circuit   \n",
      "1           1       sepang          Sepang International Circuit   \n",
      "2           2      bahrain         Bahrain International Circuit   \n",
      "3           3    catalunya        Circuit de Barcelona-Catalunya   \n",
      "4           4     istanbul                         Istanbul Park   \n",
      "..        ...          ...                                   ...   \n",
      "72         72     portimao    Autódromo Internacional do Algarve   \n",
      "73         73      mugello  Autodromo Internazionale del Mugello   \n",
      "74         74       jeddah               Jeddah Corniche Circuit   \n",
      "75         75       losail          Losail International Circuit   \n",
      "76         76        miami         Miami International Autodrome   \n",
      "\n",
      "        location       country       lat        lng    alt  \n",
      "0      Melbourne     Australia -37.84970  144.96800   10.0  \n",
      "1   Kuala Lumpur      Malaysia   2.76083  101.73800   18.0  \n",
      "2         Sakhir       Bahrain  26.03250   50.51060    7.0  \n",
      "3       Montmeló         Spain  41.57000    2.26111  109.0  \n",
      "4       Istanbul        Turkey  40.95170   29.40500  130.0  \n",
      "..           ...           ...       ...        ...    ...  \n",
      "72      Portimão      Portugal  37.22700   -8.62670  108.0  \n",
      "73       Mugello         Italy  43.99750   11.37190  255.0  \n",
      "74        Jeddah  Saudi Arabia  21.63190   39.10440   15.0  \n",
      "75     Al Daayen         Qatar  25.49000   51.45420   15.0  \n",
      "76         Miami           USA  25.95810  -80.23890    2.0  \n",
      "\n",
      "[77 rows x 8 columns]\n",
      "[]\n",
      "races\n",
      "     raceId  year  round  circuitId                  name                date  \\\n",
      "0         0  1950      1          8    British Grand Prix 1950-05-13 00:00:00   \n",
      "1         1  1950      2          5     Monaco Grand Prix 1950-05-21 00:00:00   \n",
      "2         2  1950      3         18      Indianapolis 500 1950-05-30 00:00:00   \n",
      "3         3  1950      4         65      Swiss Grand Prix 1950-06-04 00:00:00   \n",
      "4         4  1950      5         12    Belgian Grand Prix 1950-06-18 00:00:00   \n",
      "..      ...   ...    ...        ...                   ...                 ...   \n",
      "815     815  2009     13         13    Italian Grand Prix 2009-09-13 12:00:00   \n",
      "816     816  2009     14         14  Singapore Grand Prix 2009-09-27 12:00:00   \n",
      "817     817  2009     15         21   Japanese Grand Prix 2009-10-04 05:00:00   \n",
      "818     818  2009     16         17  Brazilian Grand Prix 2009-10-18 16:00:00   \n",
      "819     819  2009     17         23  Abu Dhabi Grand Prix 2009-11-01 11:00:00   \n",
      "\n",
      "         time  \n",
      "0    00:00:00  \n",
      "1    00:00:00  \n",
      "2    00:00:00  \n",
      "3    00:00:00  \n",
      "4    00:00:00  \n",
      "..        ...  \n",
      "815  12:00:00  \n",
      "816  12:00:00  \n",
      "817  05:00:00  \n",
      "818  16:00:00  \n",
      "819  11:00:00  \n",
      "\n",
      "[820 rows x 7 columns]\n",
      "[]\n",
      "drivers\n",
      "     driverId        driverRef code  forename     surname        dob  \\\n",
      "0           0         hamilton  HAM     Lewis    Hamilton 1985-01-07   \n",
      "1           1         heidfeld  HEI      Nick    Heidfeld 1977-05-10   \n",
      "2           2          rosberg  ROS      Nico     Rosberg 1985-06-27   \n",
      "3           3           alonso  ALO  Fernando      Alonso 1981-07-29   \n",
      "4           4       kovalainen  KOV    Heikki  Kovalainen 1981-10-19   \n",
      "..        ...              ...  ...       ...         ...        ...   \n",
      "852       852  mick_schumacher  MSC      Mick  Schumacher 1999-03-22   \n",
      "853       853             zhou  ZHO    Guanyu        Zhou 1999-05-30   \n",
      "854       854         de_vries  DEV      Nyck    de Vries 1995-02-06   \n",
      "855       855          piastri  PIA     Oscar     Piastri 2001-04-06   \n",
      "856       856         sargeant  SAR     Logan    Sargeant 2000-12-31   \n",
      "\n",
      "    nationality  \n",
      "0       British  \n",
      "1        German  \n",
      "2        German  \n",
      "3       Spanish  \n",
      "4       Finnish  \n",
      "..          ...  \n",
      "852      German  \n",
      "853     Chinese  \n",
      "854       Dutch  \n",
      "855  Australian  \n",
      "856    American  \n",
      "\n",
      "[857 rows x 7 columns]\n",
      "[]\n",
      "constructor_standings\n",
      "       constructorStandingsId  raceId  constructorId  points  position  wins  \\\n",
      "0                           0      64            103     3.0         3     0   \n",
      "1                           1      64              5     6.0         2     0   \n",
      "2                           2      64             85     8.0         1     1   \n",
      "3                           3      65             85    16.0         1     2   \n",
      "4                           4      65             31     0.0         5     0   \n",
      "...                       ...     ...            ...     ...       ...   ...   \n",
      "10165                   10165     819              3    26.0         8     0   \n",
      "10166                   10166     819              1    36.0         6     0   \n",
      "10167                   10167     819              2    34.5         7     0   \n",
      "10168                   10168     819              4     8.0        10     0   \n",
      "10169                   10169     819              9    13.0         9     0   \n",
      "\n",
      "                     date  \n",
      "0     1958-01-19 00:00:00  \n",
      "1     1958-01-19 00:00:00  \n",
      "2     1958-01-19 00:00:00  \n",
      "3     1958-05-18 00:00:00  \n",
      "4     1958-05-18 00:00:00  \n",
      "...                   ...  \n",
      "10165 2009-11-01 11:00:00  \n",
      "10166 2009-11-01 11:00:00  \n",
      "10167 2009-11-01 11:00:00  \n",
      "10168 2009-11-01 11:00:00  \n",
      "10169 2009-11-01 11:00:00  \n",
      "\n",
      "[10170 rows x 7 columns]\n",
      "[]\n",
      "standings\n",
      "       driverStandingsId  raceId  driverId  points  position  wins  \\\n",
      "0                      0       0       789     0.0        20     0   \n",
      "1                      1       0       640     0.0        18     0   \n",
      "2                      2       0       589     0.0        19     0   \n",
      "3                      3       0       669     0.0        15     0   \n",
      "4                      4       0       661     0.0        22     0   \n",
      "...                  ...     ...       ...     ...       ...   ...   \n",
      "28110              28110     819         7    48.0         6     1   \n",
      "28111              28111     819        68     0.0        25     0   \n",
      "28112              28112     819        11     0.0        21     0   \n",
      "28113              28113     819         6     2.0        19     0   \n",
      "28114              28114     819        12    22.0        11     0   \n",
      "\n",
      "                     date  \n",
      "0     1950-05-13 00:00:00  \n",
      "1     1950-05-13 00:00:00  \n",
      "2     1950-05-13 00:00:00  \n",
      "3     1950-05-13 00:00:00  \n",
      "4     1950-05-13 00:00:00  \n",
      "...                   ...  \n",
      "28110 2009-11-01 11:00:00  \n",
      "28111 2009-11-01 11:00:00  \n",
      "28112 2009-11-01 11:00:00  \n",
      "28113 2009-11-01 11:00:00  \n",
      "28114 2009-11-01 11:00:00  \n",
      "\n",
      "[28115 rows x 7 columns]\n",
      "[]\n",
      "constructor_results\n",
      "      constructorResultsId  raceId  constructorId  points                date\n",
      "0                        0      48            103    13.0 1956-01-22 00:00:00\n",
      "1                        1      48              5    12.0 1956-01-22 00:00:00\n",
      "2                        2      54            126     0.0 1956-08-05 00:00:00\n",
      "3                        3      54            103    15.0 1956-08-05 00:00:00\n",
      "4                        4      54              5     9.0 1956-08-05 00:00:00\n",
      "...                    ...     ...            ...     ...                 ...\n",
      "9403                  9403     819              5     0.0 2009-11-01 11:00:00\n",
      "9404                  9404     819              0     0.0 2009-11-01 11:00:00\n",
      "9405                  9405     819              2     0.0 2009-11-01 11:00:00\n",
      "9406                  9406     819              4     1.0 2009-11-01 11:00:00\n",
      "9407                  9407     819              6     5.0 2009-11-01 11:00:00\n",
      "\n",
      "[9408 rows x 5 columns]\n",
      "[]\n",
      "results\n",
      "       resultId  raceId  driverId  constructorId  number  grid  position  \\\n",
      "0             0       0       660            152    18.0    21      11.0   \n",
      "1             1       0       790            149     8.0    12       NaN   \n",
      "2             2       0       579             49     1.0     3       NaN   \n",
      "3             3       0       661            149     9.0    10       NaN   \n",
      "4             4       0       789            152    17.0     7       NaN   \n",
      "...         ...     ...       ...            ...     ...   ...       ...   \n",
      "20318     20318     819         1              1     6.0     8       5.0   \n",
      "20319     20319     819        21             22    23.0     4       4.0   \n",
      "20320     20320     819        17             22    22.0     5       3.0   \n",
      "20321     20321     819        16              8    14.0     3       2.0   \n",
      "20322     20322     819         2              2    16.0     9       9.0   \n",
      "\n",
      "       positionOrder  points  laps  milliseconds  fastestLap  rank  statusId  \\\n",
      "0                 11     0.0    64           NaN         NaN   NaN        16   \n",
      "1                 21     0.0     2           NaN         NaN   NaN       126   \n",
      "2                 12     0.0    62           NaN         NaN   NaN        44   \n",
      "3                 20     0.0     5           NaN         NaN   NaN         6   \n",
      "4                 19     0.0     8           NaN         NaN   NaN        51   \n",
      "...              ...     ...   ...           ...         ...   ...       ...   \n",
      "20318              5     4.0    55     5669667.0        54.0   7.0         1   \n",
      "20319              4     5.0    55     5666149.0        54.0   4.0         1   \n",
      "20320              3     6.0    55     5661881.0        49.0   6.0         1   \n",
      "20321              2     8.0    55     5661271.0        14.0   5.0         1   \n",
      "20322              9     0.0    55     5689355.0        49.0  15.0         1   \n",
      "\n",
      "                     date  \n",
      "0     1950-05-13 00:00:00  \n",
      "1     1950-05-13 00:00:00  \n",
      "2     1950-05-13 00:00:00  \n",
      "3     1950-05-13 00:00:00  \n",
      "4     1950-05-13 00:00:00  \n",
      "...                   ...  \n",
      "20318 2009-11-01 11:00:00  \n",
      "20319 2009-11-01 11:00:00  \n",
      "20320 2009-11-01 11:00:00  \n",
      "20321 2009-11-01 11:00:00  \n",
      "20322 2009-11-01 11:00:00  \n",
      "\n",
      "[20323 rows x 15 columns]\n",
      "['number', 'position', 'milliseconds', 'fastestLap', 'rank']\n",
      "qualifying\n",
      "      qualifyId  raceId  driverId  constructorId  number  position  \\\n",
      "0             0     548        43             26      26        19   \n",
      "1             1     548       100             30      31        26   \n",
      "2             2     548        91             29      34        25   \n",
      "3             3     548        82             31      11        24   \n",
      "4             4     548       105             32      19        23   \n",
      "...         ...     ...       ...            ...     ...       ...   \n",
      "4077       4077     819        21             22      23         4   \n",
      "4078       4078     819        16              8      14         3   \n",
      "4079       4079     819        19              8      15         2   \n",
      "4080       4080     819         0              0       1         1   \n",
      "4081       4081     819        66              4      12        10   \n",
      "\n",
      "                    date  \n",
      "0    1994-03-26 00:00:00  \n",
      "1    1994-03-26 00:00:00  \n",
      "2    1994-03-26 00:00:00  \n",
      "3    1994-03-26 00:00:00  \n",
      "4    1994-03-26 00:00:00  \n",
      "...                  ...  \n",
      "4077 2009-10-31 11:00:00  \n",
      "4078 2009-10-31 11:00:00  \n",
      "4079 2009-10-31 11:00:00  \n",
      "4080 2009-10-31 11:00:00  \n",
      "4081 2009-10-31 11:00:00  \n",
      "\n",
      "[4082 rows x 7 columns]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for table_name in db.table_dict.keys():\n",
    "    print(table_name)\n",
    "    print(db.table_dict[table_name].df)\n",
    "    df_ = db.table_dict[table_name].df\n",
    "    nan_columns = df_.columns[df_.isna().any()].tolist()\n",
    "    print(nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultId</th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>position</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>laps</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>fastestLap</th>\n",
       "      <th>rank</th>\n",
       "      <th>statusId</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18109</th>\n",
       "      <td>18109</td>\n",
       "      <td>713</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18110</th>\n",
       "      <td>18110</td>\n",
       "      <td>713</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18111</th>\n",
       "      <td>18111</td>\n",
       "      <td>713</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18112</th>\n",
       "      <td>18112</td>\n",
       "      <td>713</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18113</th>\n",
       "      <td>18113</td>\n",
       "      <td>713</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>62</td>\n",
       "      <td>2004-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20318</th>\n",
       "      <td>20318</td>\n",
       "      <td>819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5669667.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20319</th>\n",
       "      <td>20319</td>\n",
       "      <td>819</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5666149.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20320</th>\n",
       "      <td>20320</td>\n",
       "      <td>819</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5661881.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20321</th>\n",
       "      <td>20321</td>\n",
       "      <td>819</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5661271.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20322</th>\n",
       "      <td>20322</td>\n",
       "      <td>819</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5689355.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-11-01 11:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2101 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       resultId  raceId  driverId  constructorId  number  grid  position  \\\n",
       "18109     18109     713        43              6    17.0    18      13.0   \n",
       "18110     18110     713        44             16    19.0    16      14.0   \n",
       "18111     18111     713        12             14    12.0    11       NaN   \n",
       "18112     18112     713        42              6    16.0    13      12.0   \n",
       "18113     18113     713        45             17    20.0    20       NaN   \n",
       "...         ...     ...       ...            ...     ...   ...       ...   \n",
       "20318     20318     819         1              1     6.0     8       5.0   \n",
       "20319     20319     819        21             22    23.0     4       4.0   \n",
       "20320     20320     819        17             22    22.0     5       3.0   \n",
       "20321     20321     819        16              8    14.0     3       2.0   \n",
       "20322     20322     819         2              2    16.0     9       9.0   \n",
       "\n",
       "       positionOrder  points  laps  milliseconds  fastestLap  rank  statusId  \\\n",
       "18109             13     0.0    56           NaN        35.0  14.0        12   \n",
       "18110             14     0.0    55           NaN        15.0  18.0        13   \n",
       "18111             15     0.0    44           NaN        11.0  12.0         5   \n",
       "18112             12     0.0    56           NaN        41.0  15.0        12   \n",
       "18113             17     0.0    43           NaN        10.0  19.0        62   \n",
       "...              ...     ...   ...           ...         ...   ...       ...   \n",
       "20318              5     4.0    55     5669667.0        54.0   7.0         1   \n",
       "20319              4     5.0    55     5666149.0        54.0   4.0         1   \n",
       "20320              3     6.0    55     5661881.0        49.0   6.0         1   \n",
       "20321              2     8.0    55     5661271.0        14.0   5.0         1   \n",
       "20322              9     0.0    55     5689355.0        49.0  15.0         1   \n",
       "\n",
       "                     date  \n",
       "18109 2004-03-07 00:00:00  \n",
       "18110 2004-03-07 00:00:00  \n",
       "18111 2004-03-07 00:00:00  \n",
       "18112 2004-03-07 00:00:00  \n",
       "18113 2004-03-07 00:00:00  \n",
       "...                   ...  \n",
       "20318 2009-11-01 11:00:00  \n",
       "20319 2009-11-01 11:00:00  \n",
       "20320 2009-11-01 11:00:00  \n",
       "20321 2009-11-01 11:00:00  \n",
       "20322 2009-11-01 11:00:00  \n",
       "\n",
       "[2101 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = db.table_dict[\"results\"].df\n",
    "table[~table[\"fastestLap\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sm3uYXqXkbZt"
   },
   "source": [
    "If trying a new dataset, you should definitely check through this dict of `stype`s to check that look right, and manually change any mistakes by the auto-detection function.\n",
    "\n",
    "Next we also define our text encoding model, which we use GloVe embeddings for speed and convenience. Feel free to try alternatives here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQHYmgIxkX1j",
    "outputId": "2bb3bdd4-6547-4575-8740-af68c44b0450"
   },
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers # we need another package for text encoding\n",
    "from typing import List, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device\n",
    "                                       ] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "L-BBpUrakdwY",
    "outputId": "fb150ef3-c1b2-4c11-8167-28bcc789d6b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n",
      "/home/lema/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tf_dict, col_stats = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from relbench.modeling.graph import make_pkey_fkey_graph\n",
    "\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
    ")\n",
    "\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
    "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
    "    cache_dir=os.path.join(\n",
    "        root_dir, f\"rel-f1_materialized_cache\"\n",
    "    ),  # store materialized graph for convenience\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwQejmg0kzOg"
   },
   "source": [
    "We can now check out `data`, our main graph object. `data` is a heterogeneous and temporal graph, with node types given by the table it originates from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "Gt4a8lw1kufy",
    "outputId": "9c126f47-22d1-41d3-a4e3-541428389ad0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  constructors={ tf=TensorFrame([211, 3]) },\n",
       "  circuits={ tf=TensorFrame([77, 7]) },\n",
       "  races={\n",
       "    tf=TensorFrame([820, 5]),\n",
       "    time=[820],\n",
       "  },\n",
       "  drivers={ tf=TensorFrame([857, 6]) },\n",
       "  constructor_standings={\n",
       "    tf=TensorFrame([10170, 4]),\n",
       "    time=[10170],\n",
       "  },\n",
       "  standings={\n",
       "    tf=TensorFrame([28115, 4]),\n",
       "    time=[28115],\n",
       "  },\n",
       "  constructor_results={\n",
       "    tf=TensorFrame([9408, 2]),\n",
       "    time=[9408],\n",
       "  },\n",
       "  results={\n",
       "    tf=TensorFrame([20323, 11]),\n",
       "    time=[20323],\n",
       "  },\n",
       "  qualifying={\n",
       "    tf=TensorFrame([4082, 3]),\n",
       "    time=[4082],\n",
       "  },\n",
       "  (races, f2p_circuitId, circuits)={ edge_index=[2, 820] },\n",
       "  (circuits, rev_f2p_circuitId, races)={ edge_index=[2, 820] },\n",
       "  (constructor_standings, f2p_raceId, races)={ edge_index=[2, 10170] },\n",
       "  (races, rev_f2p_raceId, constructor_standings)={ edge_index=[2, 10170] },\n",
       "  (constructor_standings, f2p_constructorId, constructors)={ edge_index=[2, 10170] },\n",
       "  (constructors, rev_f2p_constructorId, constructor_standings)={ edge_index=[2, 10170] },\n",
       "  (standings, f2p_raceId, races)={ edge_index=[2, 28115] },\n",
       "  (races, rev_f2p_raceId, standings)={ edge_index=[2, 28115] },\n",
       "  (standings, f2p_driverId, drivers)={ edge_index=[2, 28115] },\n",
       "  (drivers, rev_f2p_driverId, standings)={ edge_index=[2, 28115] },\n",
       "  (constructor_results, f2p_raceId, races)={ edge_index=[2, 9408] },\n",
       "  (races, rev_f2p_raceId, constructor_results)={ edge_index=[2, 9408] },\n",
       "  (constructor_results, f2p_constructorId, constructors)={ edge_index=[2, 9408] },\n",
       "  (constructors, rev_f2p_constructorId, constructor_results)={ edge_index=[2, 9408] },\n",
       "  (results, f2p_raceId, races)={ edge_index=[2, 20323] },\n",
       "  (races, rev_f2p_raceId, results)={ edge_index=[2, 20323] },\n",
       "  (results, f2p_driverId, drivers)={ edge_index=[2, 20323] },\n",
       "  (drivers, rev_f2p_driverId, results)={ edge_index=[2, 20323] },\n",
       "  (results, f2p_constructorId, constructors)={ edge_index=[2, 20323] },\n",
       "  (constructors, rev_f2p_constructorId, results)={ edge_index=[2, 20323] },\n",
       "  (qualifying, f2p_raceId, races)={ edge_index=[2, 4082] },\n",
       "  (races, rev_f2p_raceId, qualifying)={ edge_index=[2, 4082] },\n",
       "  (qualifying, f2p_driverId, drivers)={ edge_index=[2, 4082] },\n",
       "  (drivers, rev_f2p_driverId, qualifying)={ edge_index=[2, 4082] },\n",
       "  (qualifying, f2p_constructorId, constructors)={ edge_index=[2, 4082] },\n",
       "  (constructors, rev_f2p_constructorId, qualifying)={ edge_index=[2, 4082] }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd6DqCXgk41x"
   },
   "source": [
    "We can also check out the TensorFrame for one table like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  constructors={ tf=TensorFrame([211, 3]) },\n",
       "  circuits={ tf=TensorFrame([77, 7]) },\n",
       "  races={\n",
       "    tf=TensorFrame([820, 5]),\n",
       "    time=[820],\n",
       "  },\n",
       "  drivers={ tf=TensorFrame([857, 6]) },\n",
       "  constructor_standings={\n",
       "    tf=TensorFrame([10170, 4]),\n",
       "    time=[10170],\n",
       "  },\n",
       "  standings={\n",
       "    tf=TensorFrame([28115, 4]),\n",
       "    time=[28115],\n",
       "  },\n",
       "  constructor_results={\n",
       "    tf=TensorFrame([9408, 2]),\n",
       "    time=[9408],\n",
       "  },\n",
       "  results={\n",
       "    tf=TensorFrame([20323, 11]),\n",
       "    time=[20323],\n",
       "  },\n",
       "  qualifying={\n",
       "    tf=TensorFrame([4082, 3]),\n",
       "    time=[4082],\n",
       "  },\n",
       "  (races, f2p_circuitId, circuits)={ edge_index=[2, 820] },\n",
       "  (circuits, rev_f2p_circuitId, races)={ edge_index=[2, 820] },\n",
       "  (constructor_standings, f2p_raceId, races)={ edge_index=[2, 10170] },\n",
       "  (races, rev_f2p_raceId, constructor_standings)={ edge_index=[2, 10170] },\n",
       "  (constructor_standings, f2p_constructorId, constructors)={ edge_index=[2, 10170] },\n",
       "  (constructors, rev_f2p_constructorId, constructor_standings)={ edge_index=[2, 10170] },\n",
       "  (standings, f2p_raceId, races)={ edge_index=[2, 28115] },\n",
       "  (races, rev_f2p_raceId, standings)={ edge_index=[2, 28115] },\n",
       "  (standings, f2p_driverId, drivers)={ edge_index=[2, 28115] },\n",
       "  (drivers, rev_f2p_driverId, standings)={ edge_index=[2, 28115] },\n",
       "  (constructor_results, f2p_raceId, races)={ edge_index=[2, 9408] },\n",
       "  (races, rev_f2p_raceId, constructor_results)={ edge_index=[2, 9408] },\n",
       "  (constructor_results, f2p_constructorId, constructors)={ edge_index=[2, 9408] },\n",
       "  (constructors, rev_f2p_constructorId, constructor_results)={ edge_index=[2, 9408] },\n",
       "  (results, f2p_raceId, races)={ edge_index=[2, 20323] },\n",
       "  (races, rev_f2p_raceId, results)={ edge_index=[2, 20323] },\n",
       "  (results, f2p_driverId, drivers)={ edge_index=[2, 20323] },\n",
       "  (drivers, rev_f2p_driverId, results)={ edge_index=[2, 20323] },\n",
       "  (results, f2p_constructorId, constructors)={ edge_index=[2, 20323] },\n",
       "  (constructors, rev_f2p_constructorId, results)={ edge_index=[2, 20323] },\n",
       "  (qualifying, f2p_raceId, races)={ edge_index=[2, 4082] },\n",
       "  (races, rev_f2p_raceId, qualifying)={ edge_index=[2, 4082] },\n",
       "  (qualifying, f2p_driverId, drivers)={ edge_index=[2, 4082] },\n",
       "  (drivers, rev_f2p_driverId, qualifying)={ edge_index=[2, 4082] },\n",
       "  (qualifying, f2p_constructorId, constructors)={ edge_index=[2, 4082] },\n",
       "  (constructors, rev_f2p_constructorId, qualifying)={ edge_index=[2, 4082] }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "-mMQTQeLk1rl",
    "outputId": "ad625923-623b-4d3d-8fe3-3de2cbf584c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=5,\n",
       "  num_rows=820,\n",
       "  categorical (1): ['year'],\n",
       "  numerical (1): ['round'],\n",
       "  timestamp (2): ['date', 'time'],\n",
       "  embedding (1): ['name'],\n",
       "  has_target=False,\n",
       "  device='cpu',\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"races\"].tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kbysKXMk-3X"
   },
   "source": [
    "This may be a little confusing at first, as in graph ML it is more standard to associate to the graph object `data` a tensor, e.g., `data.x` for which `data.x[idx]` is a 1D array/tensor storing all the features for node with index `idx`.\n",
    "\n",
    "But actually this `data` object behaves similarly. For a given node type, e.g., `races` again, `data['races']` stores two pieces of information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDIcp7L5k6pU",
    "outputId": "be742ecb-02db-43e6-9c12-53fb00e51fec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf', 'time']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data[\"races\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z18qPRPllB1H"
   },
   "source": [
    "A `TensorFrame` object, and a timestamp for each node. The `TensorFrame` object acts analogously to the usual tensor of node features, and you can simply use indexing to retrieve the features of a single row (node), or group of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Im8bhNh5lFG6",
    "outputId": "7ae1e0bd-746a-4164-fc95-124e302c816d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=5,\n",
       "  num_rows=1,\n",
       "  categorical (1): ['year'],\n",
       "  numerical (1): ['round'],\n",
       "  timestamp (2): ['date', 'time'],\n",
       "  embedding (1): ['name'],\n",
       "  has_target=False,\n",
       "  device='cpu',\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"races\"].tf[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYZ28pzNlG4s",
    "outputId": "1066a167-2e3b-4ad6-d929-02acf18cad0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=5,\n",
       "  num_rows=10,\n",
       "  categorical (1): ['year'],\n",
       "  numerical (1): ['round'],\n",
       "  timestamp (2): ['date', 'time'],\n",
       "  embedding (1): ['name'],\n",
       "  has_target=False,\n",
       "  device='cpu',\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"races\"].tf[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql15svcelK3A"
   },
   "source": [
    "We can also check the edge indices between two different node types, such as `races` amd `circuits`. Note that the edges are also heterogenous, so we also need to specify which edge type we want to look at. Here we look at `f2p_curcuitId`, which are the directed edges pointing _from_ a race (the `f` stands for `foreign key`), _to_ the circuit at which te race happened (the `p` stands for `primary key`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TynkD36QlInL",
    "outputId": "abc2f80d-5ff4-42b1-f9e3-bd9f004d84ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[  0,   1,   2,  ..., 817, 818, 819],\n",
       "        [  8,   5,  18,  ...,  21,  17,  23]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(\"races\", \"f2p_circuitId\", \"circuits\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx4V5KCelNxl"
   },
   "source": [
    "Now we are ready to instantiate our data loaders. For this we will need to import PyTorch Geometric, our GNN library. Whilst we're at it let's add a seed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HUHVG-g6lM-b"
   },
   "outputs": [],
   "source": [
    "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "loader_dict = {}\n",
    "\n",
    "for split, table in [\n",
    "    (\"train\", train_table),\n",
    "    (\"val\", val_table),\n",
    "    (\"test\", test_table),\n",
    "]:\n",
    "    table_input = get_node_train_table_input(\n",
    "        table=table,\n",
    "        task=task,\n",
    "    )\n",
    "    entity_table = table_input.nodes[0]\n",
    "    loader_dict[split] = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=[\n",
    "            128 for i in range(2)\n",
    "            # 64 for i in range(2)\n",
    "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
    "        time_attr=\"time\",\n",
    "        input_nodes=table_input.nodes,\n",
    "        input_time=table_input.time,\n",
    "        transform=table_input.transform,\n",
    "        batch_size=512,\n",
    "        temporal_strategy=\"uniform\",\n",
    "        shuffle=split == \"train\",\n",
    "        num_workers=0,\n",
    "        persistent_workers=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in loader_dict[\"train\"]:\n",
    "#     batch = batch.to(device)\n",
    "#     print(batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQc8BWsGludR"
   },
   "source": [
    "Now we need our model...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import torch_geometric.backend\n",
    "import torch_geometric.typing\n",
    "from torch_geometric import is_compiling\n",
    "from torch_geometric.index import index2ptr\n",
    "from torch_geometric.nn import inits\n",
    "from torch_geometric.typing import pyg_lib\n",
    "from torch_geometric.utils import index_sort\n",
    "\n",
    "\n",
    "def is_uninitialized_parameter(x: Any) -> bool:\n",
    "    if not hasattr(torch.nn.parameter, 'UninitializedParameter'):\n",
    "        return False\n",
    "    return isinstance(x, torch.nn.parameter.UninitializedParameter)\n",
    "\n",
    "\n",
    "def reset_weight_(weight: Tensor, in_channels: int,\n",
    "                  num_blocks: int, block_size: int, initializer: Optional[str] = None) -> Tensor:\n",
    "    if in_channels <= 0:\n",
    "        pass\n",
    "    elif initializer == 'glorot':\n",
    "        inits.glorot(weight)\n",
    "    elif initializer == 'uniform':\n",
    "        bound = 1.0 / math.sqrt(in_channels)\n",
    "        torch.nn.init.uniform_(weight.data, -bound, bound)\n",
    "    elif initializer == 'kaiming_uniform':\n",
    "        inits.kaiming_uniform(weight, fan=in_channels, a=math.sqrt(5))\n",
    "    elif initializer is None:\n",
    "        inits.kaiming_uniform(weight, fan=in_channels, a=math.sqrt(5))\n",
    "    else:\n",
    "        raise RuntimeError(f\"Weight initializer '{initializer}' not supported\")\n",
    "\n",
    "    return weight\n",
    "    \n",
    "\n",
    "# def reset_weight_(weight: Tensor, in_channels: int,\n",
    "#                   num_blocks: int, block_size: int, initializer: Optional[str] = None) -> Tensor:\n",
    "#     # w = torch.empty(self.block_size[0], self.block_size[1])\n",
    "#     if in_channels <= 0:\n",
    "#         pass\n",
    "#     else:\n",
    "#         with torch.no_grad():\n",
    "#             for i in range(num_blocks):\n",
    "#                 start0 = i * block_size[0]\n",
    "#                 end0 = start0 + block_size[0]\n",
    "                \n",
    "#                 start1 = i * block_size[1]\n",
    "#                 end1 = start1 + block_size[1]\n",
    "                \n",
    "                \n",
    "#                 weight[start0:end0, start1:end1] = torch.nn.init.kaiming_uniform_(\n",
    "#                 torch.empty(block_size), a=math.sqrt(5))\n",
    "                \n",
    "#     # self.weight[start0:end0, start1:end1] = inits.kaiming_uniform(\n",
    "#     #     , fan=self.in_channels, a=math.sqrt(5))\n",
    "\n",
    "#     return weight\n",
    "    \n",
    "\n",
    "def reset_bias_(bias: Optional[Tensor], in_channels: int,\n",
    "                initializer: Optional[str] = None) -> Optional[Tensor]:\n",
    "    if bias is None or in_channels <= 0:\n",
    "        pass\n",
    "    elif initializer == 'zeros':\n",
    "        inits.zeros(bias)\n",
    "    elif initializer is None:\n",
    "        inits.uniform(in_channels, bias)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Bias initializer '{initializer}' not supported\")\n",
    "\n",
    "    return bias\n",
    "\n",
    "\n",
    "class BlockDiagonalLinear(torch.nn.Module):\n",
    "    r\"\"\"Applies a linear transformation to the incoming data.\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime} = \\mathbf{x} \\mathbf{W}^{\\top} + \\mathbf{b}\n",
    "\n",
    "    In contrast to :class:`torch.nn.Linear`, it supports lazy initialization\n",
    "    and customizable weight and bias initialization.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample. Will be initialized\n",
    "            lazily in case it is given as :obj:`-1`.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        weight_initializer (str, optional): The initializer for the weight\n",
    "            matrix (:obj:`\"glorot\"`, :obj:`\"uniform\"`, :obj:`\"kaiming_uniform\"`\n",
    "            or :obj:`None`).\n",
    "            If set to :obj:`None`, will match default weight initialization of\n",
    "            :class:`torch.nn.Linear`. (default: :obj:`None`)\n",
    "        bias_initializer (str, optional): The initializer for the bias vector\n",
    "            (:obj:`\"zeros\"` or :obj:`None`).\n",
    "            If set to :obj:`None`, will match default bias initialization of\n",
    "            :class:`torch.nn.Linear`. (default: :obj:`None`)\n",
    "\n",
    "    Shapes:\n",
    "        - **input:** features :math:`(*, F_{in})`\n",
    "        - **output:** features :math:`(*, F_{out})`\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias: bool = True,\n",
    "        num_blocks: int = 1,\n",
    "        weight_initializer: Optional[str] = None,\n",
    "        bias_initializer: Optional[str] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels      \n",
    "        self.weight_initializer = weight_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        \n",
    "        self.num_blocks = num_blocks\n",
    "        assert in_channels % num_blocks == 0 \n",
    "        assert out_channels % num_blocks == 0\n",
    "        self.block_size = (in_channels // num_blocks, out_channels // num_blocks) # TODO order\n",
    "        \n",
    "        print(self.block_size, self.num_blocks)\n",
    "\n",
    "        if in_channels > 0:\n",
    "            self.weight = Parameter(torch.empty(out_channels, in_channels))\n",
    "        else:\n",
    "            self.weight = torch.nn.parameter.UninitializedParameter()\n",
    "            self._hook = self.register_forward_pre_hook(\n",
    "                self.initialize_parameters)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        # PyTorch<1.13 cannot handle deep copies of uninitialized parameters :(\n",
    "        # TODO Drop this code once PyTorch 1.12 is no longer supported.\n",
    "        out = BlockDiagonalLinear(\n",
    "            self.in_channels,\n",
    "            self.out_channels,\n",
    "            self.bias is not None,\n",
    "            self.weight_initializer,\n",
    "            self.bias_initializer,\n",
    "        ).to(self.weight.device)\n",
    "\n",
    "        if self.in_channels > 0:\n",
    "            out.weight = copy.deepcopy(self.weight, memo)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out.bias = copy.deepcopy(self.bias, memo)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    # def reset_weight_(self) -> Tensor:\n",
    "    #     # w = torch.empty(self.block_size[0], self.block_size[1])\n",
    "    #     if self.in_channels <= 0:\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         with torch.no_grad():\n",
    "    #             for i in range(self.num_blocks):\n",
    "    #                 start0 = i * self.block_size[0]\n",
    "    #                 end0 = start0 + self.block_size[0]\n",
    "                    \n",
    "    #                 start1 = i * self.block_size[1]\n",
    "    #                 end1 = start1 + self.block_size[1]\n",
    "                    \n",
    "                    \n",
    "    #                 self.weight[start0:end0, start1:end1] = torch.nn.init.kaiming_uniform_(\n",
    "    #                 torch.empty(self.block_size), a=math.sqrt(5))\n",
    "                    \n",
    "    #     # self.weight[start0:end0, start1:end1] = inits.kaiming_uniform(\n",
    "    #     #     , fan=self.in_channels, a=math.sqrt(5))\n",
    "\n",
    "    #     return self.weight\n",
    "    \n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        self.weight = reset_weight_(self.weight, self.in_channels, self.num_blocks, self.block_size)\n",
    "        reset_bias_(self.bias, self.in_channels, self.bias_initializer)\n",
    "        \n",
    "    def enforce_block_diagonal(self):\n",
    "        # Zero out non-block diagonal elements\n",
    "        with torch.no_grad():\n",
    "            mask = torch.zeros_like(self.weight)\n",
    "            for i in range(self.num_blocks):\n",
    "                start0 = i * self.block_size[0]\n",
    "                end0 = start0 + self.block_size[0]\n",
    "                \n",
    "                start1 = i * self.block_size[1]\n",
    "                end1 = start1 + self.block_size[1]\n",
    "                \n",
    "                self.weight[start0:end0, start1:end1] = 1\n",
    "            self.weight *= mask\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        r\"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input features.\n",
    "        \"\"\"\n",
    "        # self.enforce_block_diagonal()\n",
    "        F.linear(x, self.weight, self.bias)       \n",
    "        \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def initialize_parameters(self, module, input):\n",
    "        if is_uninitialized_parameter(self.weight):\n",
    "            self.in_channels = input[0].size(-1)\n",
    "            self.weight.materialize((self.out_channels, self.in_channels))\n",
    "            self.reset_parameters()\n",
    "        self._hook.remove()\n",
    "        delattr(self, '_hook')\n",
    "\n",
    "    def _save_to_state_dict(self, destination, prefix, keep_vars):\n",
    "        if (is_uninitialized_parameter(self.weight)\n",
    "                or torch.onnx.is_in_onnx_export() or keep_vars):\n",
    "            destination[prefix + 'weight'] = self.weight\n",
    "        else:\n",
    "            destination[prefix + 'weight'] = self.weight.detach()\n",
    "        if self.bias is not None:\n",
    "            if torch.onnx.is_in_onnx_export() or keep_vars:\n",
    "                destination[prefix + 'bias'] = self.bias\n",
    "            else:\n",
    "                destination[prefix + 'bias'] = self.bias.detach()\n",
    "\n",
    "    def _load_from_state_dict(self, state_dict, prefix, *args, **kwargs):\n",
    "        weight = state_dict.get(prefix + 'weight', None)\n",
    "\n",
    "        if weight is not None and is_uninitialized_parameter(weight):\n",
    "            self.in_channels = -1\n",
    "            self.weight = torch.nn.parameter.UninitializedParameter()\n",
    "            if not hasattr(self, '_hook'):\n",
    "                self._hook = self.register_forward_pre_hook(\n",
    "                    self.initialize_parameters)\n",
    "\n",
    "        elif weight is not None and is_uninitialized_parameter(self.weight):\n",
    "            self.in_channels = weight.size(-1)\n",
    "            self.weight.materialize((self.out_channels, self.in_channels))\n",
    "            if hasattr(self, '_hook'):\n",
    "                self._hook.remove()\n",
    "                delattr(self, '_hook')\n",
    "\n",
    "        super()._load_from_state_dict(state_dict, prefix, *args, **kwargs)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, bias={self.bias is not None})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.nn.aggr import Aggregation, MultiAggregation\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "# from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptPairTensor, Size, SparseTensor\n",
    "from torch_geometric.utils import spmm\n",
    "\n",
    "class MySAGEConv(MessagePassing):\n",
    "    r\"\"\"The GraphSAGE operator from the `\"Inductive Representation Learning on\n",
    "    Large Graphs\" <https://arxiv.org/abs/1706.02216>`_ paper.\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{W}_1 \\mathbf{x}_i + \\mathbf{W}_2 \\cdot\n",
    "        \\mathrm{mean}_{j \\in \\mathcal{N(i)}} \\mathbf{x}_j\n",
    "\n",
    "    If :obj:`project = True`, then :math:`\\mathbf{x}_j` will first get\n",
    "    projected via\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}_j \\leftarrow \\sigma ( \\mathbf{W}_3 \\mathbf{x}_j +\n",
    "        \\mathbf{b})\n",
    "\n",
    "    as described in Eq. (3) of the paper.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample, or :obj:`-1` to\n",
    "            derive the size from the first input(s) to the forward method.\n",
    "            A tuple corresponds to the sizes of source and target\n",
    "            dimensionalities.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        aggr (str or Aggregation, optional): The aggregation scheme to use.\n",
    "            Any aggregation of :obj:`torch_geometric.nn.aggr` can be used,\n",
    "            *e.g.*, :obj:`\"mean\"`, :obj:`\"max\"`, or :obj:`\"lstm\"`.\n",
    "            (default: :obj:`\"mean\"`)\n",
    "        normalize (bool, optional): If set to :obj:`True`, output features\n",
    "            will be :math:`\\ell_2`-normalized, *i.e.*,\n",
    "            :math:`\\frac{\\mathbf{x}^{\\prime}_i}\n",
    "            {\\| \\mathbf{x}^{\\prime}_i \\|_2}`.\n",
    "            (default: :obj:`False`)\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        project (bool, optional): If set to :obj:`True`, the layer will apply a\n",
    "            linear transformation followed by an activation function before\n",
    "            aggregation (as described in Eq. (3) of the paper).\n",
    "            (default: :obj:`False`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "\n",
    "    Shapes:\n",
    "        - **inputs:**\n",
    "          node features :math:`(|\\mathcal{V}|, F_{in})` or\n",
    "          :math:`((|\\mathcal{V_s}|, F_{s}), (|\\mathcal{V_t}|, F_{t}))`\n",
    "          if bipartite,\n",
    "          edge indices :math:`(2, |\\mathcal{E}|)`\n",
    "        - **outputs:** node features :math:`(|\\mathcal{V}|, F_{out})` or\n",
    "          :math:`(|\\mathcal{V_t}|, F_{out})` if bipartite\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        aggr: Optional[Union[str, List[str], Aggregation]] = \"mean\",\n",
    "        normalize: bool = False,\n",
    "        root_weight: bool = True,\n",
    "        project: bool = False,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.root_weight = root_weight\n",
    "        self.project = project\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        if aggr == 'lstm':\n",
    "            kwargs.setdefault('aggr_kwargs', {})\n",
    "            kwargs['aggr_kwargs'].setdefault('in_channels', in_channels[0])\n",
    "            kwargs['aggr_kwargs'].setdefault('out_channels', in_channels[0])\n",
    "\n",
    "        super().__init__(aggr, **kwargs)\n",
    "\n",
    "        if self.project:\n",
    "            if in_channels[0] <= 0:\n",
    "                raise ValueError(f\"'{self.__class__.__name__}' does not \"\n",
    "                                 f\"support lazy initialization with \"\n",
    "                                 f\"`project=True`\")\n",
    "            self.lin = BlockDiagonalLinear(in_channels[0], in_channels[0], bias=True)\n",
    "\n",
    "        if isinstance(self.aggr_module, MultiAggregation):\n",
    "            aggr_out_channels = self.aggr_module.get_out_channels(\n",
    "                in_channels[0])\n",
    "        else:\n",
    "            aggr_out_channels = in_channels[0]\n",
    "\n",
    "        self.lin_l = BlockDiagonalLinear(aggr_out_channels, out_channels, bias=bias)\n",
    "        if self.root_weight:\n",
    "            self.lin_r = BlockDiagonalLinear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        if self.project:\n",
    "            self.lin.reset_parameters()\n",
    "        self.lin_l.reset_parameters()\n",
    "        if self.root_weight:\n",
    "            self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Union[Tensor, OptPairTensor],\n",
    "        edge_index: Adj,\n",
    "        size: Size = None,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        if isinstance(x, Tensor):\n",
    "            x = (x, x)\n",
    "\n",
    "        if self.project and hasattr(self, 'lin'):\n",
    "            x = (self.lin(x[0]).relu(), x[1])\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor)\n",
    "        out = self.propagate(edge_index, x=x, size=size)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if self.root_weight and x_r is not None:\n",
    "            out = out + self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2., dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: Adj, x: OptPairTensor) -> Tensor:\n",
    "        if isinstance(adj_t, SparseTensor):\n",
    "            adj_t = adj_t.set_value(None, layout=None)\n",
    "        return spmm(adj_t, x[0], reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, aggr={self.aggr})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import torch_frame\n",
    "from torch import Tensor\n",
    "from torch_frame.data.stats import StatType\n",
    "from torch_frame.nn.models import ResNet\n",
    "from torch_geometric.nn import HeteroConv, LayerNorm, PositionalEncoding\n",
    "from torch_geometric.typing import EdgeType, NodeType\n",
    "\n",
    "class MyHeteroGraphSAGE(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_types: List[NodeType],\n",
    "        edge_types: List[EdgeType],\n",
    "        channels: int,\n",
    "        aggr: str = \"mean\",\n",
    "        num_layers: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv(\n",
    "                {\n",
    "                    edge_type: MySAGEConv((channels, channels), channels, aggr=aggr)\n",
    "                    for edge_type in edge_types\n",
    "                },\n",
    "                aggr=\"sum\",\n",
    "            )\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            norm_dict = torch.nn.ModuleDict()\n",
    "            for node_type in node_types:\n",
    "                norm_dict[node_type] = LayerNorm(channels, mode=\"node\")\n",
    "            self.norms.append(norm_dict)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for norm_dict in self.norms:\n",
    "            for norm in norm_dict.values():\n",
    "                norm.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_dict: Dict[NodeType, Tensor],\n",
    "        edge_index_dict: Dict[NodeType, Tensor],\n",
    "        num_sampled_nodes_dict: Optional[Dict[NodeType, List[int]]] = None,\n",
    "        num_sampled_edges_dict: Optional[Dict[EdgeType, List[int]]] = None,\n",
    "    ) -> Dict[NodeType, Tensor]:\n",
    "        for _, (conv, norm_dict) in enumerate(zip(self.convs, self.norms)):\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: norm_dict[key](x) for key, x in x_dict.items()}\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id awareness, num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "u3m3jEqClQnw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n",
      "(128, 128) 1\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "import copy\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Embedding, ModuleDict\n",
    "from torch_frame.data.stats import StatType\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.typing import NodeType\n",
    "\n",
    "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: HeteroData,\n",
    "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
    "        num_layers: int,\n",
    "        channels: int,\n",
    "        out_channels: int,\n",
    "        aggr: str,\n",
    "        norm: str,\n",
    "        # List of node types to add shallow embeddings to input\n",
    "        shallow_list: List[NodeType] = [],\n",
    "        # ID awareness\n",
    "        id_awareness: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = HeteroEncoder(\n",
    "            channels=channels,\n",
    "            node_to_col_names_dict={\n",
    "                node_type: data[node_type].tf.col_names_dict\n",
    "                for node_type in data.node_types\n",
    "            },\n",
    "            node_to_col_stats=col_stats_dict,\n",
    "        )\n",
    "        self.temporal_encoder = HeteroTemporalEncoder(\n",
    "            node_types=[\n",
    "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
    "            ],\n",
    "            channels=channels,\n",
    "        )\n",
    "        self.gnn = MyHeteroGraphSAGE(\n",
    "            node_types=data.node_types,\n",
    "            edge_types=data.edge_types,\n",
    "            channels=channels,\n",
    "            aggr=aggr,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.head = MLP(\n",
    "            channels,\n",
    "            out_channels=out_channels,\n",
    "            norm=norm,\n",
    "            num_layers=1,\n",
    "        )\n",
    "        self.embedding_dict = ModuleDict(\n",
    "            {\n",
    "                node: Embedding(data.num_nodes_dict[node], channels)\n",
    "                for node in shallow_list\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.id_awareness_emb = None\n",
    "        if id_awareness:\n",
    "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.encoder.reset_parameters()\n",
    "        self.temporal_encoder.reset_parameters()\n",
    "        self.gnn.reset_parameters()\n",
    "        self.head.reset_parameters()\n",
    "        for embedding in self.embedding_dict.values():\n",
    "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
    "        if self.id_awareness_emb is not None:\n",
    "            self.id_awareness_emb.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch: HeteroData,\n",
    "        entity_table: NodeType,\n",
    "    ) -> Tensor:\n",
    "        seed_time = batch[entity_table].seed_time\n",
    "        # print(\"seed_time\",seed_time)\n",
    "        x_dict = self.encoder(batch.tf_dict)\n",
    "\n",
    "        rel_time_dict = self.temporal_encoder(\n",
    "            seed_time, batch.time_dict, batch.batch_dict\n",
    "        )\n",
    "        \n",
    "        # merge the embeddings\n",
    "        for node_type, rel_time in rel_time_dict.items():\n",
    "            # print(\"rel_time embedding shape\",rel_time.shape)\n",
    "            # print(\"rel_time embedding\",rel_time)\n",
    "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
    "\n",
    "        for node_type, embedding in self.embedding_dict.items():\n",
    "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
    "\n",
    "        x_dict = self.gnn(\n",
    "            x_dict,\n",
    "            batch.edge_index_dict,\n",
    "            batch.num_sampled_nodes_dict,\n",
    "            batch.num_sampled_edges_dict,\n",
    "        )\n",
    "\n",
    "        return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
    "# never used\n",
    "\"\"\"     def forward_dst_readout(\n",
    "        self,\n",
    "        batch: HeteroData,\n",
    "        entity_table: NodeType,\n",
    "        dst_table: NodeType,\n",
    "    ) -> Tensor:\n",
    "        if self.id_awareness_emb is None:\n",
    "            raise RuntimeError(\n",
    "                \"id_awareness must be set True to use forward_dst_readout\"\n",
    "            )\n",
    "        seed_time = batch[entity_table].seed_time\n",
    "        x_dict = self.encoder(batch.tf_dict)\n",
    "        # Add ID-awareness to the root node\n",
    "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
    "\n",
    "        rel_time_dict = self.temporal_encoder(\n",
    "            seed_time, batch.time_dict, batch.batch_dict\n",
    "        )\n",
    "\n",
    "        for node_type, rel_time in rel_time_dict.items():\n",
    "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
    "\n",
    "        for node_type, embedding in self.embedding_dict.items():\n",
    "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
    "\n",
    "        x_dict = self.gnn(\n",
    "            x_dict,\n",
    "            batch.edge_index_dict,\n",
    "        )\n",
    "\n",
    "        return self.head(x_dict[dst_table]) \"\"\"\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=2,\n",
    "    channels=128, # dim embeddingov (vmes), neodvisno\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# if you try out different RelBench tasks you will need to change these\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl-6So7Llb-p"
   },
   "source": [
    "We also need standard train/test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SAHRIr15lVs6"
   },
   "outputs": [],
   "source": [
    "def train() -> float:\n",
    "    model.train()\n",
    "\n",
    "    loss_accum = count_accum = 0\n",
    "    for batch in tqdm(loader_dict[\"train\"]):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(\n",
    "            batch,\n",
    "            task.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "\n",
    "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_accum += loss.detach().item() * pred.size(0)\n",
    "        count_accum += pred.size(0)\n",
    "\n",
    "    return loss_accum / count_accum\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: NeighborLoader) -> np.ndarray:\n",
    "    model.eval()\n",
    "\n",
    "    pred_list = []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(\n",
    "            batch,\n",
    "            task.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        pred_list.append(pred.detach().cpu())\n",
    "    return torch.cat(pred_list, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s-p7dW1ledd"
   },
   "source": [
    "Now we are ready to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yF3W68Eqlew_",
    "outputId": "a81a48dc-234a-47f3-8759-8dc9a766661c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m best_val_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39minf \u001b[38;5;28;01mif\u001b[39;00m higher_is_better \u001b[38;5;28;01melse\u001b[39;00m math\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     val_pred \u001b[38;5;241m=\u001b[39m test(loader_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m     val_metrics \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mevaluate(val_pred, val_table)\n",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m pred\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m pred\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred\u001b[38;5;241m.\u001b[39mfloat(), batch[entity_table]\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m~/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[24], line 105\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, batch, entity_table)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_type, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    103\u001b[0m     x_dict[node_type] \u001b[38;5;241m=\u001b[39m x_dict[node_type] \u001b[38;5;241m+\u001b[39m embedding(batch[node_type]\u001b[38;5;241m.\u001b[39mn_id)\n\u001b[0;32m--> 105\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_sampled_nodes_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_sampled_edges_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x_dict[entity_table][: seed_time\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)])\n",
      "File \u001b[0;32m~/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[23], line 55\u001b[0m, in \u001b[0;36mMyHeteroGraphSAGE.forward\u001b[0;34m(self, x_dict, edge_index_dict, num_sampled_nodes_dict, num_sampled_edges_dict)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     49\u001b[0m     x_dict: Dict[NodeType, Tensor],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     num_sampled_edges_dict: Optional[Dict[EdgeType, List[\u001b[38;5;28mint\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     53\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[NodeType, Tensor]:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, (conv, norm_dict) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms)):\n\u001b[0;32m---> 55\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m {key: norm_dict[key](x) \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     57\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m {key: x\u001b[38;5;241m.\u001b[39mrelu() \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch_geometric/nn/conv/hetero_conv.py:158\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[0;34m(self, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[1;32m    161\u001b[0m     out_dict[dst] \u001b[38;5;241m=\u001b[39m [out]\n",
      "File \u001b[0;32m~/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/faks/MLG/machine_learning_on_graphs/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[22], line 138\u001b[0m, in \u001b[0;36mMySAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    136\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_weight \u001b[38;5;129;01mand\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize:\n\u001b[1;32m    141\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(out, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "state_dict = None\n",
    "best_val_metric = -math.inf if higher_is_better else math.inf\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train()\n",
    "    val_pred = test(loader_dict[\"val\"])\n",
    "    val_metrics = task.evaluate(val_pred, val_table)\n",
    "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
    "\n",
    "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
    "        not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
    "    ):\n",
    "        best_val_metric = val_metrics[tune_metric]\n",
    "        state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "val_pred = test(loader_dict[\"val\"])\n",
    "val_metrics = task.evaluate(val_pred, val_table)\n",
    "print(f\"Best Val metrics: {val_metrics}\")\n",
    "\n",
    "test_pred = test(loader_dict[\"test\"])\n",
    "test_metrics = task.evaluate(test_pred)\n",
    "print(f\"Best test metrics: {test_metrics}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metrics.out\", \"w\") as f:\n",
    "    f.write(f\"Best Val metrics: {list(map(float, val_metrics.values()))}\\n\".replace(\",\",\"\"))\n",
    "    f.write(f\"Best test metrics: {list(map(float, test_metrics.values()))}\\n\".replace(\",\",\"\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
